<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Build tools in machine learning projects, an overview / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/en\/post\/451962\/"},"headline":"Build tools in machine learning projects, an overview","datePublished":"2019-05-20T12:39:38+03:00","dateModified":"2019-05-20T23:45:10+03:00","author":{"@type":"Person","name":"Vadim Frolov"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"I was wondering about machine learning\/data science project structure\/workflow and was reading different opinions on the subject. And when people start to talk...","url":"https:\/\/habr.com\/en\/post\/451962\/#post-content-body","about":["h_machine_learning","h_build_automation","f_develop"],"image":["https:\/\/habrastorage.org\/getpro\/habr\/post_images\/aff\/fbf\/656\/afffbf6566a6e67ea6427d28d76d7eea.png","https:\/\/habrastorage.org\/webt\/oo\/za\/pj\/oozapjujvjg_q86ndg6r7c5u36a.png","https:\/\/habrastorage.org\/webt\/xh\/te\/ol\/xhteolpanywbjxanltb8uxdsoly.png","https:\/\/habrastorage.org\/getpro\/habr\/post_images\/ba2\/95c\/bb9\/ba295cbb9b744767e709aa7b3a0e358f.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Build tools in machine learning projects, an overview" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Build tools in machine learning projects, an overview" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Build tools in machine learning projects, an overview" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="I was wondering about machine learning/data science project structure/workflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="I was wondering about machine learning/data science project structure/workflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="I was wondering about machine learning/data science project structure/workflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="I was wondering about machine learning/data science project structure/workflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="I was wondering about machine learning/data science project structure/workflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habr.com/share/publication/451962/eec41c344b3ef0376b56feee86419a83/" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habr.com/share/publication/451962/eec41c344b3ef0376b56feee86419a83/" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habr.com/share/publication/451962/eec41c344b3ef0376b56feee86419a83/" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habr.com/share/publication/451962/eec41c344b3ef0376b56feee86419a83/" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habr.com/share/publication/451962/eec41c344b3ef0376b56feee86419a83/" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="451962" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2019-05-20T09:39:38.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="en_US" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/451962/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/en/post/451962/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habr.com/share/publication/451962/eec41c344b3ef0376b56feee86419a83/" data-vmid="image:href">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/fralik/" title="fralik" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/b27/fc0/fba/b27fc0fba890b43e70e41a36a9b27aca.png" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/fralik/" class="tm-user-info__username">
      fralik
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2019-05-20T09:39:38.000Z" title="2019-05-20, 12:39">20  мая  2019 в 12:39</time></span></div> <!----></div> <h1 lang="en" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Build tools in machine learning projects, an overview</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/build_automation/" class="tm-article-snippet__hubs-item-link"><span>Системы сборки</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="en" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml">I was wondering about machine learning/data science project structure/workflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows to be reproducible. There are a lot of posts out there that suggest to use <a href="https://www.gnu.org/software/make/">make</a> for keeping workflow reproducible. Although <code>make</code> is very stable and widely-used I personally like cross-platform solutions. It is 2019 after all, not 1977. One can argue that make itself is cross-platform, but in reality you will have troubles and will spend time on fixing your tool rather than on doing the actual work. So I decided to have a look around and to check out what other tools are available. Yes, I decided to spend some time on tools.<br/>
<br/>
<div style="text-align:center;"><img src="/img/image-loader.svg" alt="image" data-src="https://habrastorage.org/getpro/habr/post_images/aff/fbf/656/afffbf6566a6e67ea6427d28d76d7eea.png"/></div><br/>
This post is more an invitation for a dialogue rather than a tutorial. Perhaps your solution is perfect. If it is then it will be interesting to hear about it.<br/>
<br/>
In this post I will use a small Python project and will do the same automation tasks with different systems:<br/>
<br/>
<ul>
<li><a href="https://cmake.org/">CMake</a></li>
<li><a href="https://pybuilder.github.io/">PyBuilder</a></li>
<li><a href="https://github.com/rags/pynt">pynt</a></li>
<li><a href="https://github.com/paver/paver">Paver</a></li>
<li><a href="http://pydoit.org/">doit</a></li>
<li><a href="https://github.com/spotify/luigi">Luigi</a></li>
</ul><br/>
There will be a <a href="#Comparison">comparison table</a> in the end of the post.<br/>
<a name="habracut"></a><br/>
Most of the tools I will look at are known as <em>build automation software</em> or <em>build systems</em>. There are myriads of them in all different flavours, sizes and complexities. The idea is the same: developer defines rules for producing some results in an automated and consistent way. For example, a result might be an image with a graph. In order to make this image one would need to download the data, clean the data and do some data manipulations (classical example, really). You may start with a couple of shell scripts that will do the job. Once you return to the project a year later, it will be difficult to remember all the steps and their order you need to take to make that image. The obvious solution is to document all the steps. Good news! Build systems let you document the steps in a form of computer program. Some build systems are like your shell scripts, but with additional bells and whistles.<br/>
<br/>
The foundation of this post is a series of posts by <a href="https://towardsdatascience.com/structure-and-automated-workflow-for-a-machine-learning-project-2fa30d661c1e">Mateusz Bednarski</a> on automated workflow for a machine learning project. Mateusz explains his views and provides recipes for using <code>make</code>. I encourage you to go and check his posts first. I will mostly use his code, but with different build systems.<br/>
<br/>
If you would like to know more about <code>make</code>, following is a references for a couple of posts. <a href="https://medium.com/opex-analytics/5-easy-steps-to-make-your-data-science-project-reproducible-6254ab36c365">Brooke Kennedy</a> gives a high-level overview in 5 Easy Steps to Make Your Data Science Project Reproducible. <a href="http://zmjones.com/make/">Zachary Jones</a> gives more details about the syntax and capabilities along with the links to other posts. <a href="https://medium.com/@davidstevens_16424/make-my-day-ta-science-easier-e16bc50e719c">David Stevens</a> writes a very hype post on why you absolutely have to start using <code>make</code> right away. He provides nice examples comparing <i>the old way</i> and <i>the new way</i>. <a href="https://bionics.it/posts/the-problem-with-make-for-scientific-workflows">Samuel Lampa</a>, on the other hand, writes about why using <code>make</code> is a bad idea.<br/>
<br/>
My selection of build systems is not comprehensive nor unbiased. If you want to make your list, <a href="https://en.wikipedia.org/wiki/List_of_build_automation_software">Wikipedia</a> might be a good starting point. As stated above above, I will cover <a href="#CMake">CMake</a>, <a href="#PyBuilder">PyBuilder</a>, <a href="#pynt">pynt</a>, <a href="#Paver">Paver</a>, <a href="#doit">doit</a> and <a href="#Luigi">Luigi</a>. Most of the tools in this list are python-based and it makes sense since the project is in Python. This post will not cover how to install the tools. I assume that you are fairly proficient in Python.<br/>
<br/>
I am mostly interested in testing this functionality:<br/>
<br/>
<ol>
<li>Specifying couple of targets with dependencies. I want to see how to do it and how easy it is.</li>
<li>Checking out if incremental builds are possible. This means that build system won’t rebuild what have not been changed since the last run, i.e. you do not need to redownload your raw data. Another thing that I will look for is incremental builds when dependency changes. Imagine we have a graph of dependencies <code>A -> B -> C</code>. Will target <code>C</code> be rebuilt if <code>B</code> changes? If <code>A</code>?</li>
<li>Checking if rebuild will be triggered if source code is changed, i.e. we change the parameter of generated graph, next time we build the image must be rebuilt.</li>
<li>Checking out the ways to clean build artifacts, i.e. remove files that have been created during build and roll back to the clean source code.</li>
</ol><br/>
I will not use all build targets from Mateusz's post, just three of them to illustrate the principles.<br/>
<br/>
All the code is available on <a href="https://github.com/fralik/overcome-the-chaos">GitHub</a>.<br/>
<br/>
<h2><a name="CMake"></a>CMake</h2><br/>
CMake is a build script generator, which generates input files for various build systems. And it’s name stands for cross-platform make. CMake is a software engineering tool. It’s primary concern is about building executables and libraries. So CMake knows how to build <i>targets</i> from source code in supported languages. CMake is executed in two steps: configuration and generation. During configuration it is possible to configure the future build according to one needs. For example, user-provided variables are given during this step. Generation is normally straightforward and produces file(s) that build systems can work with. With CMake, you can still use <code>make</code>, but instead of writing makefile directly you write a CMake file, which will generate the makefile for you.<br/>
<br/>
Another important concept is that CMake encourages <i>out-of-source builds</i>. Out-of-source builds keep source code away from any artifacts it produces. This makes a lot of sense for executables where single source codebase may be compiled under different CPU architectures and operating systems. This approach, however, may contradict the way a lot of data scientists work. It seems to me that data science community tends to have high coupling of data, code and results.<br/>
<br/>
Let’s see what we need to achieve our goals with CMake. There are two possibilities to define custom things in CMake: custom targets and custom commands. Unfortunately we will need to use both, which results in more typing compared to vanila makefile. A custom target is considered to be always out of date, i.e. if there is a target for downloading raw data CMake will always redownload it. A combination of custom command with custom target allows to keep targets up to date.<br/>
<br/>
For our project we will create a file named <a href="https://github.com/fralik/overcome-the-chaos/blob/master/CMakeLists.txt">CMakeLists.txt</a> and put it in the project’s root. Let’s check out the content:<br/>
<br/>
<pre><code class="cmake">cmake_minimum_required(VERSION 3.14.0 FATAL_ERROR)
project(Cmake_in_ml VERSION 0.1.0 LANGUAGES NONE)
</code></pre><br/>
This part is basic. The second line defines the name of your project, version, and specifies that we won’t use any build-in language support (sine we will call Python scripts).<br/>
<br/>
Our first target will download the IRIS dataset:<br/>
<br/>
<pre><code class="cmake">SET(IRIS_URL "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data" CACHE STRING "URL to the IRIS data")
set(IRIS_DIR ${CMAKE_CURRENT_SOURCE_DIR}/data/raw)
set(IRIS_FILE ${IRIS_DIR}/iris.csv)
ADD_CUSTOM_COMMAND(OUTPUT ${IRIS_FILE}
    COMMAND ${CMAKE_COMMAND} -E echo "Downloading IRIS."
    COMMAND python src/data/download.py ${IRIS_URL} ${IRIS_FILE}
    COMMAND ${CMAKE_COMMAND} -E echo "Done. Checkout ${IRIS_FILE}."
    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
    )
ADD_CUSTOM_TARGET(rawdata ALL DEPENDS ${IRIS_FILE})
</code></pre><br/>
First line defines parameter <code>IRIS_URL</code>, which is exposed to user during configuration step. If you use CMake GUI you can set this variable through the GUI:<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/oo/za/pj/oozapjujvjg_q86ndg6r7c5u36a.png"/><br/>
<br/>
Next, we define variables with downloaded location of IRIS dataset. Then we add a custom command, which will produce <code>IRIS_FILE</code> as it’s output. In the end, we define a custom target <code>rawdata</code> that depends on <code>IRIS_FILE</code> meaning that in order to build <code>rawdata</code> <code>IRIS_FILE</code> must be built. Option <code>ALL</code> of custom target says that <code>rawdata</code> will be one of the default targets to build. Note that I use <code>CMAKE_CURRENT_SOURCE_DIR</code> in order to keep the downloaded data in the source folder and not in the build folder. This is just to make it the same as Mateusz.<br/>
<br/>
Alright, let’s see how we can use it. I am currently running it on WIndows with installed MinGW compiler. You may need to adjust the generator setting for your needs (run <code>cmake --help</code> to see the list of available generators). Fire up the terminal and go to the parent folder of the source code, then:<br/>
<br/>
<pre><code class="bash">mkdir overcome-the-chaos-build
cd overcome-the-chaos-build
cmake -G "MinGW Makefiles" ../overcome-the-chaos
</code></pre><br/>
<div class="spoiler"><b class="spoiler_title">outcome</b><div class="spoiler_text"> — Configuring done<br/>
 — Generating done<br/>
 — Build files have been written to: C:/home/workspace/overcome-the-chaos-build<br/>
</div></div><br/>
With modern CMake we can build the project directly from CMake. This command will invoke <code>build all</code> command:<br/>
<br/>
<pre><code class="bash">cmake --build .
</code></pre><br/>
<div class="spoiler"><b class="spoiler_title">outcome</b><div class="spoiler_text">Scanning dependencies of target rawdata<br/>
[100%] Built target rawdata<br/>
</div></div><br/>
We can also view the list of available targets:<br/>
<br/>
<pre><code class="bash">cmake --build . --target help
</code></pre><br/>
And we can remove downloaded file by:<br/>
<br/>
<pre><code class="bash">cmake --build . --target clean
</code></pre><br/>
See that we didn’t need to create the clean target manually.<br/>
<br/>
Now let’s move to the next target — preprocessed IRIS data. Mateusz creates two files from a single function: <code>processed.pickle</code> and <code>processed.xlsx</code>. You can see how he goes away with cleaning this Excel file by using <code>rm</code> with wildcard. I think this is not a very good approach. In CMake, we have two options of how to deal with it. First option is to use <a href="https://cmake.org/cmake/help/latest/prop_dir/ADDITIONAL_MAKE_CLEAN_FILES.html">ADDITIONAL_MAKE_CLEAN_FILES</a> directory property. The code will be:<br/>
<br/>
<pre><code class="cmake">SET(PROCESSED_FILE ${CMAKE_CURRENT_SOURCE_DIR}/data/processed/processed.pickle)
ADD_CUSTOM_COMMAND(OUTPUT ${PROCESSED_FILE}
    COMMAND python src/data/preprocess.py ${IRIS_FILE} ${PROCESSED_FILE} --excel data/processed/processed.xlsx
    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
    DEPENDS rawdata ${IRIS_FILE}
    )
ADD_CUSTOM_TARGET(preprocess DEPENDS ${PROCESSED_FILE})
# Additional files to clean
set_property(DIRECTORY PROPERTY ADDITIONAL_MAKE_CLEAN_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/data/processed/processed.xlsx
    )
</code></pre><br/>
The second option is to specify a list of files as a custom command output:<br/>
<br/>
<pre><code class="cmake">LIST(APPEND PROCESSED_FILE "${CMAKE_CURRENT_SOURCE_DIR}/data/processed/processed.pickle"
    "${CMAKE_CURRENT_SOURCE_DIR}/data/processed/processed.xlsx"
    )
ADD_CUSTOM_COMMAND(OUTPUT ${PROCESSED_FILE}
    COMMAND python src/data/preprocess.py ${IRIS_FILE} data/processed/processed.pickle --excel data/processed/processed.xlsx
    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
    DEPENDS rawdata ${IRIS_FILE} src/data/preprocess.py
    )
ADD_CUSTOM_TARGET(preprocess DEPENDS ${PROCESSED_FILE})
</code></pre><br/>
See that in this case I created the list, but didn’t use it inside custom command. I do not know of a way to reference output arguments of custom command inside it.<br/>
<br/>
Another interesting thing to note is the usage of <code>depends</code> in this custom command. We set dependency not only from a custom target, but it’s output as well and the python script. If we do not add dependency to <code>IRIS_FILE</code>, then modifying <code>iris.csv</code> manually will not result in rebuilding of <code>preprocess</code> target. Well, you should not modify files in your build directory manually in the first place. Just letting you know. More details in <a href="https://samthursfield.wordpress.com/2015/11/21/cmake-dependencies-between-targets-and-files-and-custom-commands/">Sam Thursfield's post</a>. The dependency to python script is needed to rebuild the target if python script changes.<br/>
<br/>
And finally the third target:<br/>
<br/>
<pre><code class="cmake">SET(EXPLORATORY_IMG ${CMAKE_CURRENT_SOURCE_DIR}/reports/figures/exploratory.png)
ADD_CUSTOM_COMMAND(OUTPUT ${EXPLORATORY_IMG}
    COMMAND python src/visualization/exploratory.py ${PROCESSED_FILE} ${EXPLORATORY_IMG}
    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
    DEPENDS ${PROCESSED_FILE} src/visualization/exploratory.py
    )
ADD_CUSTOM_TARGET(exploratory DEPENDS ${EXPLORATORY_IMG})
</code></pre><br/>
This target is basically the same as the second one.<br/>
<br/>
To wrap up. CMake looks messy and more difficult than Make. Indeed, a lot of people criticize CMake for it’s syntax. In my experience, the understanding will come and it is absolutely possible to make sense of even very complicated CMake files.<br/>
<br/>
You will still do a lot of gluing yourself as you will need to pass correct variables around. I do not see an easy way of referencing output of one custom command in another one. It seems like it is possible to do it via custom targets.<br/>
<br/>
<h2><a name="PyBuilder"></a>PyBuilder</h2><br/>
PyBuilder part is very short. I used Python 3.7 in my project and PyBuilder current version 0.11.17 does not support it. The proposed solution is to use development version. However that version is bounded to pip v9. Pip is v19.3 as of time of writing. Bummer. After fiddling around with it a bit, it didn't work for me at all. PyBuilder evaluation was a short-lived one.<br/>
<br/>
<h2><a name="pynt"></a>pynt</h2><br/>
Pynt is python-based, which means we can use python functions directly. It is not necessary to wrap them with <a href="https://click.palletsprojects.com/en/7.x/">click</a> and to provide command line interface. However, pynt is also capable of executing shell commands. I will use python functions.<br/>
<br/>
Build commands are given in a file <code>build.py</code>. Targets/tasks are created with function decorators. Task dependencies are provided through the same decorator.<br/>
<br/>
Since I would like to use python functions I need to import them in the build script. Pynt does not include the current directory as python script, so writing smth like this:<br/>
<br/>
<pre><code class="python">from src.data.download import pydownload_file
</code></pre><br/>
will not work. We have to do:<br/>
<br/>
<pre><code class="python">import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '.'))

from src.data.download import pydownload_file
</code></pre><br/>
My initial <code>build.py</code> file was like this:<br/>
<br/>
<pre><code class="python">#!/usr/bin/python

import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '.'))
from pynt import task

from path import Path
import glob

from src.data.download import pydownload_file
from src.data.preprocess import pypreprocess

iris_file = 'data/raw/iris.csv'
processed_file = 'data/processed/processed.pickle'

@task()
def rawdata():
  '''Download IRIS dataset'''
  pydownload_file('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', iris_file)

@task()
def clean():
    '''Clean all build artifacts'''
    patterns = ['data/raw/*.csv', 'data/processed/*.pickle',
            'data/processed/*.xlsx', 'reports/figures/*.png']
    for pat in patterns:
        for fl in glob.glob(pat):
            Path(fl).remove()

@task(rawdata)
def preprocess():
    '''Preprocess IRIS dataset'''
    pypreprocess(iris_file, processed_file, 'data/processed/processed.xlsx')
</code></pre><br/>
And the <code>preprocess</code> target didn't work. It was constantly complaining about input arguments of <code>pypreprocess</code> function. It seems like Pynt does not handle optional function arguments very well. I had to remove the argument for making the excel file. Keep this in mind if your project has functions with optional arguments.<br/>
<br/>
We can run pynt from the project's folder and list all the available targets:<br/>
<br/>
<pre><code class="bash">pynt -l
</code></pre><br/>
<div class="spoiler"><b class="spoiler_title">outcome</b><div class="spoiler_text"><pre><code class="bash">Tasks in build file build.py:
  clean                      Clean all build artifacts
  exploratory                Make an image with pairwise distribution
  preprocess                 Preprocess IRIS dataset
  rawdata                    Download IRIS dataset

Powered by pynt 0.8.2 - A Lightweight Python Build Tool.
</code></pre><br/>
</div></div><br/>
Let's make the pairwise distribution:<br/>
<br/>
<pre><code class="bash">pynt exploratory
</code></pre><br/>
<div class="spoiler"><b class="spoiler_title">outcome</b><div class="spoiler_text"><pre><code class="bash">[ build.py - Starting task "rawdata" ]
Downloading from https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data to data/raw/iris.csv
[ build.py - Completed task "rawdata" ]
[ build.py - Starting task "preprocess" ]
Preprocessing data
[ build.py - Completed task "preprocess" ]
[ build.py - Starting task "exploratory" ]
Plotting pairwise distribution...
[ build.py - Completed task "exploratory" ]
</code></pre><br/>
</div></div><br/>
If we now run the same command again (i.e. <code>pynt exploratory</code>) there will be a full rebuild. Pynt didn't track that nothing has changed.<br/>
<br/>
<h2><a name="Paver"></a>Paver</h2><br/>
Paver looks almost exactly as Pynt. It slightly different in a way one defines dependencies between targets (another decorator <code>@needs</code>). Paver makes a full rebuild each time and doesn't play nicely with functions that have optional arguments. Build instructions are found in <a href="https://github.com/fralik/overcome-the-chaos/blob/master/pavement.py">pavement.py</a> file.<br/>
<br/>
<h2><a name="doit"></a>doit</h2><br/>
Doit seems like an attempt to create a truly build automation tool in python. It can execute python code and shell commands. It looks quite promising. What it seems to miss (in the context of our specific goals) is the ability to handle dependencies between targets. Let's say we want to make a small pipeline where the output of target A is used as input of target B. And let's say we are using files as outputs, so target A create a file named <code>outA</code>.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/xh/te/ol/xhteolpanywbjxanltb8uxdsoly.png"/><br/>
<br/>
In order to make such pipeline we will need to specify file <code>outA</code> twice in target A (as a result of a target, but also return it's name as part of target execution). Then we will need to specify it as input to target B. So there are 3 places in total where we need to provide information about file <code>outA</code>. And even after we do so, modification of file <code>outA</code> won't lead to automatic rebuild of target B. This means that if we ask doit to build target B, doit will only check if target B is up-to-date without checking any of the dependencies. To overcome this, we will need to specify <code>outA</code> 4 times — also as file dependency of target B. I see this as a drawback. Both Make and CMake are able to handle such situations correctly.<br/>
<br/>
Dependencies in doit are file-based and expressed as strings. This means that dependencies <code>./myfile.txt</code> and <code>myfile.txt</code> are viewed as being different. As I wrote above, I find the way of passing information from target to target (when using python targets) a bit strange. Target has a list of artifacts it is going to produce, but another target can't use it. Instead the python function, which constitutes the target, must return a dictionary, which can be accessed in another target. Let's see it on an example:<br/>
<br/>
<pre><code class="python">def task_preprocess():
    """Preprocess IRIS dataset"""
    pickle_file = 'data/processed/processed.pickle'
    excel_file = 'data/processed/processed.xlsx'
    return {
        'file_dep': ['src/data/preprocess.py'],
        'targets': [pickle_file, excel_file],
        'actions': [doit_pypreprocess],
        'getargs': {'input_file': ('rawdata', 'filename')},
        'clean': True,
    }
</code></pre><br/>
Here the target <code>preprocess</code> depends on <code>rawdata</code>. The dependency is provided via <code>getargs</code> property. It says that the argument <code>input_file</code> of function <code>doit_pypreprocess</code> is the output <code>filename</code> of the target <code>rawdata</code>. Have a look at the complete example in file <a href="https://github.com/fralik/overcome-the-chaos/blob/master/dodo.py">dodo.py</a>.<br/>
<br/>
It may be worth reading <a href="http://pydoit.org/stories.html">the success stories</a> of using doit. It definitely has nice features like the ability to provide a custom up-to-date target check.<br/>
<br/>
<h2><a name="Luigi"></a>Luigi</h2><br/>
Luigi stays apart from other tools as it is a system to build complex pipelines. It appeared on my radar after a colleague told me that he tried Make, was never able to use it across Windows/Linux and moved away to Luigi.<br/>
<br/>
Luigi aims at production-ready systems. It comes with a server, which can be used to visualize your tasks or to get a history of task executions. The server is called a <em>central schedler</em>. A local scheduler is available for debugging purposes.<br/>
<br/>
Luigi is also different from other systems in a way how tasks are created. Lugi doesn't act on some predefined file (like <code>dodo.py</code>, <code>pavement.py</code> or makefile). Rather, one has to pass a python module name. So, if we try to use it in the similar way to other tools (place a file with tasks in project's root), it won't work. We have to either install our project or modify environmental variable <code>PYTHONPATH</code> by adding the path to the project.<br/>
<br/>
What is great about luigi is the way of specifying dependencies between tasks. Each task is a class. Method <code>output</code> tells Luigi where the results of the task will end up. Results can be a single element or a list. Method <code>requires</code> specifies task dependencies (other tasks; although it is possible to make a dependency from itself). And that's it. Whatever is specified as <code>output</code> in task A will be passed as an input to task B if task B relies on task A.<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/getpro/habr/post_images/ba2/95c/bb9/ba295cbb9b744767e709aa7b3a0e358f.png"/><br/>
<br/>
Luigi doesn't care about file modifications. It cares about file existance. So it is not possible to trigger rebuilds when the source code changes. Luigi doesn't have a built-in <i>clean</i> functionality.<br/>
<br/>
Luigi tasks for this project are available in file <a href="https://github.com/fralik/overcome-the-chaos/blob/master/luigitasks.py">luigitasks.py</a>. I run them from the terminal:<br/>
<br/>
<pre><code class="plaintext">luigi --local-scheduler --module luigitasks Exploratory
</code></pre><br/>
<h2><a name="Comparison"></a>Comparison</h2><br/>
The table below summarizes how different systems work in respect to our specific goals.<br/>
<div class="scrollable-table"><table>
<tr>
<th> </th>
<th>Define target with dependency</th>
<th>Incremental builds</th>
<th>Incremental builds if source code is changed</th>
<th>Ability to figure out which artifacts to remove during <code>clean</code> command</th>
</tr>
<tr>
<td><strong>CMake</strong></td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td><strong>Pynt</strong></td>
<td>yes</td>
<td>no</td>
<td>no</td>
<td>no</td>
</tr>
<tr>
<td><strong>Paver</strong></td>
<td>yes</td>
<td>no</td>
<td>no</td>
<td>no</td>
</tr>
<tr>
<td><strong>doit</strong></td>
<td>Somewhat yes</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td><strong>Luigi</strong></td>
<td>yes</td>
<td>no</td>
<td>no</td>
<td>no</td>
</tr>
</table></div></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bmake%5D" class="tm-tags-list__link">make</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bcmake%5D" class="tm-tags-list__link">cmake</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bpython%5D" class="tm-tags-list__link">python</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bpynt%5D" class="tm-tags-list__link">pynt</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bpaver%5D" class="tm-tags-list__link">paver</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bpydoit%5D" class="tm-tags-list__link">pydoit</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bluigi%5D" class="tm-tags-list__link">luigi</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bbuild%20tools%5D" class="tm-tags-list__link">build tools</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/build_automation/" class="tm-hubs-list__link">
    Системы сборки
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 9: ↑7 и ↓2</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 9: ↑7 и ↓2" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+5</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">2.3K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    4
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/fralik/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/b27/fc0/fba/b27fc0fba890b43e70e41a36a9b27aca.png" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 77 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    65
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">0</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><span class="tm-user-card__name tm-user-card__name_variant-article">Vadim Frolov</span> <a href="/ru/users/fralik/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @fralik
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Data Scientist</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <div class="tm-article-author__user-contacts"><a href="https://blog.vadimfrolov.com/" rel="noopener" target="_blank" class="tm-article-author__contact">
      Сайт
    </a></div></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/451962/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментировать 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/451962/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/451962/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"451962":{"id":"451962","timePublished":"2019-05-20T09:39:38+00:00","isCorporative":false,"lang":"en","titleHtml":"Build tools in machine learning projects, an overview","leadData":{"textHtml":"I was wondering about machine learning\u002Fdata science project structure\u002Fworkflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows to be reproducible. There are a lot of posts out there that suggest to use \u003Ca href=\"https:\u002F\u002Fwww.gnu.org\u002Fsoftware\u002Fmake\u002F\"\u003Emake\u003C\u002Fa\u003E for keeping workflow reproducible. Although \u003Ccode\u003Emake\u003C\u002Fcode\u003E is very stable and widely-used I personally like cross-platform solutions. It is 2019 after all, not 1977. One can argue that make itself is cross-platform, but in reality you will have troubles and will spend time on fixing your tool rather than on doing the actual work. So I decided to have a look around and to check out what other tools are available. Yes, I decided to spend some time on tools.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002Faff\u002Ffbf\u002F656\u002Fafffbf6566a6e67ea6427d28d76d7eea.png\" alt=\"image\"\u003E\u003C\u002Fdiv\u003E\u003Cbr\u003E\r\nThis post is more an invitation for a dialogue rather than a tutorial. Perhaps your solution is perfect. If it is then it will be interesting to hear about it.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nIn this post I will use a small Python project and will do the same automation tasks with different systems:\u003Cbr\u003E\r\n\u003Cbr\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fcmake.org\u002F\"\u003ECMake\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpybuilder.github.io\u002F\"\u003EPyBuilder\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Frags\u002Fpynt\"\u003Epynt\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fpaver\u002Fpaver\"\u003EPaver\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fpydoit.org\u002F\"\u003Edoit\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fspotify\u002Fluigi\"\u003ELuigi\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u003E\r\nThere will be a \u003Ca href=\"#Comparison\"\u003Ecomparison table\u003C\u002Fa\u003E in the end of the post.\u003Cbr\u003E","imageUrl":null,"buttonTextHtml":"Read more →","image":null},"editorVersion":"1.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":65,"votesCount":77},"rating":0,"relatedData":null,"contacts":[{"title":"Сайт","url":"https:\u002F\u002Fblog.vadimfrolov.com\u002F","value":"https:\u002F\u002Fblog.vadimfrolov.com\u002F"}],"authorContacts":[{"title":"Сайт","url":"https:\u002F\u002Fblog.vadimfrolov.com\u002F","value":"https:\u002F\u002Fblog.vadimfrolov.com\u002F"}],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"54170","alias":"fralik","fullname":"Vadim Frolov","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fb27\u002Ffc0\u002Ffba\u002Fb27fc0fba890b43e70e41a36a9b27aca.png","speciality":"Data Scientist"},"statistics":{"commentsCount":0,"favoritesCount":4,"readingCount":2318,"score":5,"votesCount":9},"hubs":[{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true},{"relatedData":null,"id":"19816","alias":"build_automation","type":"collective","title":"Системы сборки","titleHtml":"Системы сборки","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003EI was wondering about machine learning\u002Fdata science project structure\u002Fworkflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows to be reproducible. There are a lot of posts out there that suggest to use \u003Ca href=\"https:\u002F\u002Fwww.gnu.org\u002Fsoftware\u002Fmake\u002F\"\u003Emake\u003C\u002Fa\u003E for keeping workflow reproducible. Although \u003Ccode\u003Emake\u003C\u002Fcode\u003E is very stable and widely-used I personally like cross-platform solutions. It is 2019 after all, not 1977. One can argue that make itself is cross-platform, but in reality you will have troubles and will spend time on fixing your tool rather than on doing the actual work. So I decided to have a look around and to check out what other tools are available. Yes, I decided to spend some time on tools.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"image\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002Faff\u002Ffbf\u002F656\u002Fafffbf6566a6e67ea6427d28d76d7eea.png\"\u002F\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nThis post is more an invitation for a dialogue rather than a tutorial. Perhaps your solution is perfect. If it is then it will be interesting to hear about it.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nIn this post I will use a small Python project and will do the same automation tasks with different systems:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fcmake.org\u002F\"\u003ECMake\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpybuilder.github.io\u002F\"\u003EPyBuilder\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Frags\u002Fpynt\"\u003Epynt\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fpaver\u002Fpaver\"\u003EPaver\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"http:\u002F\u002Fpydoit.org\u002F\"\u003Edoit\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fspotify\u002Fluigi\"\u003ELuigi\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\nThere will be a \u003Ca href=\"#Comparison\"\u003Ecomparison table\u003C\u002Fa\u003E in the end of the post.\u003Cbr\u002F\u003E\r\n\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\nMost of the tools I will look at are known as \u003Cem\u003Ebuild automation software\u003C\u002Fem\u003E or \u003Cem\u003Ebuild systems\u003C\u002Fem\u003E. There are myriads of them in all different flavours, sizes and complexities. The idea is the same: developer defines rules for producing some results in an automated and consistent way. For example, a result might be an image with a graph. In order to make this image one would need to download the data, clean the data and do some data manipulations (classical example, really). You may start with a couple of shell scripts that will do the job. Once you return to the project a year later, it will be difficult to remember all the steps and their order you need to take to make that image. The obvious solution is to document all the steps. Good news! Build systems let you document the steps in a form of computer program. Some build systems are like your shell scripts, but with additional bells and whistles.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nThe foundation of this post is a series of posts by \u003Ca href=\"https:\u002F\u002Ftowardsdatascience.com\u002Fstructure-and-automated-workflow-for-a-machine-learning-project-2fa30d661c1e\"\u003EMateusz Bednarski\u003C\u002Fa\u003E on automated workflow for a machine learning project. Mateusz explains his views and provides recipes for using \u003Ccode\u003Emake\u003C\u002Fcode\u003E. I encourage you to go and check his posts first. I will mostly use his code, but with different build systems.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nIf you would like to know more about \u003Ccode\u003Emake\u003C\u002Fcode\u003E, following is a references for a couple of posts. \u003Ca href=\"https:\u002F\u002Fmedium.com\u002Fopex-analytics\u002F5-easy-steps-to-make-your-data-science-project-reproducible-6254ab36c365\"\u003EBrooke Kennedy\u003C\u002Fa\u003E gives a high-level overview in 5 Easy Steps to Make Your Data Science Project Reproducible. \u003Ca href=\"http:\u002F\u002Fzmjones.com\u002Fmake\u002F\"\u003EZachary Jones\u003C\u002Fa\u003E gives more details about the syntax and capabilities along with the links to other posts. \u003Ca href=\"https:\u002F\u002Fmedium.com\u002F@davidstevens_16424\u002Fmake-my-day-ta-science-easier-e16bc50e719c\"\u003EDavid Stevens\u003C\u002Fa\u003E writes a very hype post on why you absolutely have to start using \u003Ccode\u003Emake\u003C\u002Fcode\u003E right away. He provides nice examples comparing \u003Ci\u003Ethe old way\u003C\u002Fi\u003E and \u003Ci\u003Ethe new way\u003C\u002Fi\u003E. \u003Ca href=\"https:\u002F\u002Fbionics.it\u002Fposts\u002Fthe-problem-with-make-for-scientific-workflows\"\u003ESamuel Lampa\u003C\u002Fa\u003E, on the other hand, writes about why using \u003Ccode\u003Emake\u003C\u002Fcode\u003E is a bad idea.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nMy selection of build systems is not comprehensive nor unbiased. If you want to make your list, \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FList_of_build_automation_software\"\u003EWikipedia\u003C\u002Fa\u003E might be a good starting point. As stated above above, I will cover \u003Ca href=\"#CMake\"\u003ECMake\u003C\u002Fa\u003E, \u003Ca href=\"#PyBuilder\"\u003EPyBuilder\u003C\u002Fa\u003E, \u003Ca href=\"#pynt\"\u003Epynt\u003C\u002Fa\u003E, \u003Ca href=\"#Paver\"\u003EPaver\u003C\u002Fa\u003E, \u003Ca href=\"#doit\"\u003Edoit\u003C\u002Fa\u003E and \u003Ca href=\"#Luigi\"\u003ELuigi\u003C\u002Fa\u003E. Most of the tools in this list are python-based and it makes sense since the project is in Python. This post will not cover how to install the tools. I assume that you are fairly proficient in Python.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nI am mostly interested in testing this functionality:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Col\u003E\r\n\u003Cli\u003ESpecifying couple of targets with dependencies. I want to see how to do it and how easy it is.\u003C\u002Fli\u003E\r\n\u003Cli\u003EChecking out if incremental builds are possible. This means that build system won’t rebuild what have not been changed since the last run, i.e. you do not need to redownload your raw data. Another thing that I will look for is incremental builds when dependency changes. Imagine we have a graph of dependencies \u003Ccode\u003EA -\u003E B -\u003E C\u003C\u002Fcode\u003E. Will target \u003Ccode\u003EC\u003C\u002Fcode\u003E be rebuilt if \u003Ccode\u003EB\u003C\u002Fcode\u003E changes? If \u003Ccode\u003EA\u003C\u002Fcode\u003E?\u003C\u002Fli\u003E\r\n\u003Cli\u003EChecking if rebuild will be triggered if source code is changed, i.e. we change the parameter of generated graph, next time we build the image must be rebuilt.\u003C\u002Fli\u003E\r\n\u003Cli\u003EChecking out the ways to clean build artifacts, i.e. remove files that have been created during build and roll back to the clean source code.\u003C\u002Fli\u003E\r\n\u003C\u002Fol\u003E\u003Cbr\u002F\u003E\r\nI will not use all build targets from Mateusz's post, just three of them to illustrate the principles.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nAll the code is available on \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffralik\u002Fovercome-the-chaos\"\u003EGitHub\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003E\u003Ca name=\"CMake\"\u003E\u003C\u002Fa\u003ECMake\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nCMake is a build script generator, which generates input files for various build systems. And it’s name stands for cross-platform make. CMake is a software engineering tool. It’s primary concern is about building executables and libraries. So CMake knows how to build \u003Ci\u003Etargets\u003C\u002Fi\u003E from source code in supported languages. CMake is executed in two steps: configuration and generation. During configuration it is possible to configure the future build according to one needs. For example, user-provided variables are given during this step. Generation is normally straightforward and produces file(s) that build systems can work with. With CMake, you can still use \u003Ccode\u003Emake\u003C\u002Fcode\u003E, but instead of writing makefile directly you write a CMake file, which will generate the makefile for you.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nAnother important concept is that CMake encourages \u003Ci\u003Eout-of-source builds\u003C\u002Fi\u003E. Out-of-source builds keep source code away from any artifacts it produces. This makes a lot of sense for executables where single source codebase may be compiled under different CPU architectures and operating systems. This approach, however, may contradict the way a lot of data scientists work. It seems to me that data science community tends to have high coupling of data, code and results.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nLet’s see what we need to achieve our goals with CMake. There are two possibilities to define custom things in CMake: custom targets and custom commands. Unfortunately we will need to use both, which results in more typing compared to vanila makefile. A custom target is considered to be always out of date, i.e. if there is a target for downloading raw data CMake will always redownload it. A combination of custom command with custom target allows to keep targets up to date.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nFor our project we will create a file named \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffralik\u002Fovercome-the-chaos\u002Fblob\u002Fmaster\u002FCMakeLists.txt\"\u003ECMakeLists.txt\u003C\u002Fa\u003E and put it in the project’s root. Let’s check out the content:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"cmake\"\u003Ecmake_minimum_required(VERSION 3.14.0 FATAL_ERROR)\nproject(Cmake_in_ml VERSION 0.1.0 LANGUAGES NONE)\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nThis part is basic. The second line defines the name of your project, version, and specifies that we won’t use any build-in language support (sine we will call Python scripts).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nOur first target will download the IRIS dataset:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"cmake\"\u003ESET(IRIS_URL \"https:\u002F\u002Farchive.ics.uci.edu\u002Fml\u002Fmachine-learning-databases\u002Firis\u002Firis.data\" CACHE STRING \"URL to the IRIS data\")\nset(IRIS_DIR ${CMAKE_CURRENT_SOURCE_DIR}\u002Fdata\u002Fraw)\nset(IRIS_FILE ${IRIS_DIR}\u002Firis.csv)\nADD_CUSTOM_COMMAND(OUTPUT ${IRIS_FILE}\n    COMMAND ${CMAKE_COMMAND} -E echo \"Downloading IRIS.\"\n    COMMAND python src\u002Fdata\u002Fdownload.py ${IRIS_URL} ${IRIS_FILE}\n    COMMAND ${CMAKE_COMMAND} -E echo \"Done. Checkout ${IRIS_FILE}.\"\n    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n    )\nADD_CUSTOM_TARGET(rawdata ALL DEPENDS ${IRIS_FILE})\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nFirst line defines parameter \u003Ccode\u003EIRIS_URL\u003C\u002Fcode\u003E, which is exposed to user during configuration step. If you use CMake GUI you can set this variable through the GUI:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Foo\u002Fza\u002Fpj\u002Foozapjujvjg_q86ndg6r7c5u36a.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nNext, we define variables with downloaded location of IRIS dataset. Then we add a custom command, which will produce \u003Ccode\u003EIRIS_FILE\u003C\u002Fcode\u003E as it’s output. In the end, we define a custom target \u003Ccode\u003Erawdata\u003C\u002Fcode\u003E that depends on \u003Ccode\u003EIRIS_FILE\u003C\u002Fcode\u003E meaning that in order to build \u003Ccode\u003Erawdata\u003C\u002Fcode\u003E \u003Ccode\u003EIRIS_FILE\u003C\u002Fcode\u003E must be built. Option \u003Ccode\u003EALL\u003C\u002Fcode\u003E of custom target says that \u003Ccode\u003Erawdata\u003C\u002Fcode\u003E will be one of the default targets to build. Note that I use \u003Ccode\u003ECMAKE_CURRENT_SOURCE_DIR\u003C\u002Fcode\u003E in order to keep the downloaded data in the source folder and not in the build folder. This is just to make it the same as Mateusz.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nAlright, let’s see how we can use it. I am currently running it on WIndows with installed MinGW compiler. You may need to adjust the generator setting for your needs (run \u003Ccode\u003Ecmake --help\u003C\u002Fcode\u003E to see the list of available generators). Fire up the terminal and go to the parent folder of the source code, then:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"bash\"\u003Emkdir overcome-the-chaos-build\ncd overcome-the-chaos-build\ncmake -G \"MinGW Makefiles\" ..\u002Fovercome-the-chaos\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"spoiler\"\u003E\u003Cb class=\"spoiler_title\"\u003Eoutcome\u003C\u002Fb\u003E\u003Cdiv class=\"spoiler_text\"\u003E — Configuring done\u003Cbr\u002F\u003E\r\n — Generating done\u003Cbr\u002F\u003E\r\n — Build files have been written to: C:\u002Fhome\u002Fworkspace\u002Fovercome-the-chaos-build\u003Cbr\u002F\u003E\r\n\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nWith modern CMake we can build the project directly from CMake. This command will invoke \u003Ccode\u003Ebuild all\u003C\u002Fcode\u003E command:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"bash\"\u003Ecmake --build .\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"spoiler\"\u003E\u003Cb class=\"spoiler_title\"\u003Eoutcome\u003C\u002Fb\u003E\u003Cdiv class=\"spoiler_text\"\u003EScanning dependencies of target rawdata\u003Cbr\u002F\u003E\r\n[100%] Built target rawdata\u003Cbr\u002F\u003E\r\n\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nWe can also view the list of available targets:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"bash\"\u003Ecmake --build . --target help\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nAnd we can remove downloaded file by:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"bash\"\u003Ecmake --build . --target clean\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nSee that we didn’t need to create the clean target manually.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nNow let’s move to the next target — preprocessed IRIS data. Mateusz creates two files from a single function: \u003Ccode\u003Eprocessed.pickle\u003C\u002Fcode\u003E and \u003Ccode\u003Eprocessed.xlsx\u003C\u002Fcode\u003E. You can see how he goes away with cleaning this Excel file by using \u003Ccode\u003Erm\u003C\u002Fcode\u003E with wildcard. I think this is not a very good approach. In CMake, we have two options of how to deal with it. First option is to use \u003Ca href=\"https:\u002F\u002Fcmake.org\u002Fcmake\u002Fhelp\u002Flatest\u002Fprop_dir\u002FADDITIONAL_MAKE_CLEAN_FILES.html\"\u003EADDITIONAL_MAKE_CLEAN_FILES\u003C\u002Fa\u003E directory property. The code will be:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"cmake\"\u003ESET(PROCESSED_FILE ${CMAKE_CURRENT_SOURCE_DIR}\u002Fdata\u002Fprocessed\u002Fprocessed.pickle)\nADD_CUSTOM_COMMAND(OUTPUT ${PROCESSED_FILE}\n    COMMAND python src\u002Fdata\u002Fpreprocess.py ${IRIS_FILE} ${PROCESSED_FILE} --excel data\u002Fprocessed\u002Fprocessed.xlsx\n    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n    DEPENDS rawdata ${IRIS_FILE}\n    )\nADD_CUSTOM_TARGET(preprocess DEPENDS ${PROCESSED_FILE})\n# Additional files to clean\nset_property(DIRECTORY PROPERTY ADDITIONAL_MAKE_CLEAN_FILES\n    ${CMAKE_CURRENT_SOURCE_DIR}\u002Fdata\u002Fprocessed\u002Fprocessed.xlsx\n    )\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nThe second option is to specify a list of files as a custom command output:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"cmake\"\u003ELIST(APPEND PROCESSED_FILE \"${CMAKE_CURRENT_SOURCE_DIR}\u002Fdata\u002Fprocessed\u002Fprocessed.pickle\"\n    \"${CMAKE_CURRENT_SOURCE_DIR}\u002Fdata\u002Fprocessed\u002Fprocessed.xlsx\"\n    )\nADD_CUSTOM_COMMAND(OUTPUT ${PROCESSED_FILE}\n    COMMAND python src\u002Fdata\u002Fpreprocess.py ${IRIS_FILE} data\u002Fprocessed\u002Fprocessed.pickle --excel data\u002Fprocessed\u002Fprocessed.xlsx\n    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n    DEPENDS rawdata ${IRIS_FILE} src\u002Fdata\u002Fpreprocess.py\n    )\nADD_CUSTOM_TARGET(preprocess DEPENDS ${PROCESSED_FILE})\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nSee that in this case I created the list, but didn’t use it inside custom command. I do not know of a way to reference output arguments of custom command inside it.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nAnother interesting thing to note is the usage of \u003Ccode\u003Edepends\u003C\u002Fcode\u003E in this custom command. We set dependency not only from a custom target, but it’s output as well and the python script. If we do not add dependency to \u003Ccode\u003EIRIS_FILE\u003C\u002Fcode\u003E, then modifying \u003Ccode\u003Eiris.csv\u003C\u002Fcode\u003E manually will not result in rebuilding of \u003Ccode\u003Epreprocess\u003C\u002Fcode\u003E target. Well, you should not modify files in your build directory manually in the first place. Just letting you know. More details in \u003Ca href=\"https:\u002F\u002Fsamthursfield.wordpress.com\u002F2015\u002F11\u002F21\u002Fcmake-dependencies-between-targets-and-files-and-custom-commands\u002F\"\u003ESam Thursfield's post\u003C\u002Fa\u003E. The dependency to python script is needed to rebuild the target if python script changes.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nAnd finally the third target:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"cmake\"\u003ESET(EXPLORATORY_IMG ${CMAKE_CURRENT_SOURCE_DIR}\u002Freports\u002Ffigures\u002Fexploratory.png)\nADD_CUSTOM_COMMAND(OUTPUT ${EXPLORATORY_IMG}\n    COMMAND python src\u002Fvisualization\u002Fexploratory.py ${PROCESSED_FILE} ${EXPLORATORY_IMG}\n    WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n    DEPENDS ${PROCESSED_FILE} src\u002Fvisualization\u002Fexploratory.py\n    )\nADD_CUSTOM_TARGET(exploratory DEPENDS ${EXPLORATORY_IMG})\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nThis target is basically the same as the second one.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nTo wrap up. CMake looks messy and more difficult than Make. Indeed, a lot of people criticize CMake for it’s syntax. In my experience, the understanding will come and it is absolutely possible to make sense of even very complicated CMake files.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nYou will still do a lot of gluing yourself as you will need to pass correct variables around. I do not see an easy way of referencing output of one custom command in another one. It seems like it is possible to do it via custom targets.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003E\u003Ca name=\"PyBuilder\"\u003E\u003C\u002Fa\u003EPyBuilder\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nPyBuilder part is very short. I used Python 3.7 in my project and PyBuilder current version 0.11.17 does not support it. The proposed solution is to use development version. However that version is bounded to pip v9. Pip is v19.3 as of time of writing. Bummer. After fiddling around with it a bit, it didn't work for me at all. PyBuilder evaluation was a short-lived one.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003E\u003Ca name=\"pynt\"\u003E\u003C\u002Fa\u003Epynt\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nPynt is python-based, which means we can use python functions directly. It is not necessary to wrap them with \u003Ca href=\"https:\u002F\u002Fclick.palletsprojects.com\u002Fen\u002F7.x\u002F\"\u003Eclick\u003C\u002Fa\u003E and to provide command line interface. However, pynt is also capable of executing shell commands. I will use python functions.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nBuild commands are given in a file \u003Ccode\u003Ebuild.py\u003C\u002Fcode\u003E. Targets\u002Ftasks are created with function decorators. Task dependencies are provided through the same decorator.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nSince I would like to use python functions I need to import them in the build script. Pynt does not include the current directory as python script, so writing smth like this:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"python\"\u003Efrom src.data.download import pydownload_file\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nwill not work. We have to do:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"python\"\u003Eimport os\nimport sys\nsys.path.append(os.path.join(os.path.dirname(__file__), '.'))\n\nfrom src.data.download import pydownload_file\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nMy initial \u003Ccode\u003Ebuild.py\u003C\u002Fcode\u003E file was like this:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"python\"\u003E#!\u002Fusr\u002Fbin\u002Fpython\n\nimport os\nimport sys\nsys.path.append(os.path.join(os.path.dirname(__file__), '.'))\nfrom pynt import task\n\nfrom path import Path\nimport glob\n\nfrom src.data.download import pydownload_file\nfrom src.data.preprocess import pypreprocess\n\niris_file = 'data\u002Fraw\u002Firis.csv'\nprocessed_file = 'data\u002Fprocessed\u002Fprocessed.pickle'\n\n@task()\ndef rawdata():\n  '''Download IRIS dataset'''\n  pydownload_file('https:\u002F\u002Farchive.ics.uci.edu\u002Fml\u002Fmachine-learning-databases\u002Firis\u002Firis.data', iris_file)\n\n@task()\ndef clean():\n    '''Clean all build artifacts'''\n    patterns = ['data\u002Fraw\u002F*.csv', 'data\u002Fprocessed\u002F*.pickle',\n            'data\u002Fprocessed\u002F*.xlsx', 'reports\u002Ffigures\u002F*.png']\n    for pat in patterns:\n        for fl in glob.glob(pat):\n            Path(fl).remove()\n\n@task(rawdata)\ndef preprocess():\n    '''Preprocess IRIS dataset'''\n    pypreprocess(iris_file, processed_file, 'data\u002Fprocessed\u002Fprocessed.xlsx')\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nAnd the \u003Ccode\u003Epreprocess\u003C\u002Fcode\u003E target didn't work. It was constantly complaining about input arguments of \u003Ccode\u003Epypreprocess\u003C\u002Fcode\u003E function. It seems like Pynt does not handle optional function arguments very well. I had to remove the argument for making the excel file. Keep this in mind if your project has functions with optional arguments.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nWe can run pynt from the project's folder and list all the available targets:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"bash\"\u003Epynt -l\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"spoiler\"\u003E\u003Cb class=\"spoiler_title\"\u003Eoutcome\u003C\u002Fb\u003E\u003Cdiv class=\"spoiler_text\"\u003E\u003Cpre\u003E\u003Ccode class=\"bash\"\u003ETasks in build file build.py:\n  clean                      Clean all build artifacts\n  exploratory                Make an image with pairwise distribution\n  preprocess                 Preprocess IRIS dataset\n  rawdata                    Download IRIS dataset\n\nPowered by pynt 0.8.2 - A Lightweight Python Build Tool.\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nLet's make the pairwise distribution:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"bash\"\u003Epynt exploratory\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"spoiler\"\u003E\u003Cb class=\"spoiler_title\"\u003Eoutcome\u003C\u002Fb\u003E\u003Cdiv class=\"spoiler_text\"\u003E\u003Cpre\u003E\u003Ccode class=\"bash\"\u003E[ build.py - Starting task \"rawdata\" ]\nDownloading from https:\u002F\u002Farchive.ics.uci.edu\u002Fml\u002Fmachine-learning-databases\u002Firis\u002Firis.data to data\u002Fraw\u002Firis.csv\n[ build.py - Completed task \"rawdata\" ]\n[ build.py - Starting task \"preprocess\" ]\nPreprocessing data\n[ build.py - Completed task \"preprocess\" ]\n[ build.py - Starting task \"exploratory\" ]\nPlotting pairwise distribution...\n[ build.py - Completed task \"exploratory\" ]\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nIf we now run the same command again (i.e. \u003Ccode\u003Epynt exploratory\u003C\u002Fcode\u003E) there will be a full rebuild. Pynt didn't track that nothing has changed.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003E\u003Ca name=\"Paver\"\u003E\u003C\u002Fa\u003EPaver\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nPaver looks almost exactly as Pynt. It slightly different in a way one defines dependencies between targets (another decorator \u003Ccode\u003E@needs\u003C\u002Fcode\u003E). Paver makes a full rebuild each time and doesn't play nicely with functions that have optional arguments. Build instructions are found in \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffralik\u002Fovercome-the-chaos\u002Fblob\u002Fmaster\u002Fpavement.py\"\u003Epavement.py\u003C\u002Fa\u003E file.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003E\u003Ca name=\"doit\"\u003E\u003C\u002Fa\u003Edoit\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nDoit seems like an attempt to create a truly build automation tool in python. It can execute python code and shell commands. It looks quite promising. What it seems to miss (in the context of our specific goals) is the ability to handle dependencies between targets. Let's say we want to make a small pipeline where the output of target A is used as input of target B. And let's say we are using files as outputs, so target A create a file named \u003Ccode\u003EoutA\u003C\u002Fcode\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fxh\u002Fte\u002Fol\u002Fxhteolpanywbjxanltb8uxdsoly.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nIn order to make such pipeline we will need to specify file \u003Ccode\u003EoutA\u003C\u002Fcode\u003E twice in target A (as a result of a target, but also return it's name as part of target execution). Then we will need to specify it as input to target B. So there are 3 places in total where we need to provide information about file \u003Ccode\u003EoutA\u003C\u002Fcode\u003E. And even after we do so, modification of file \u003Ccode\u003EoutA\u003C\u002Fcode\u003E won't lead to automatic rebuild of target B. This means that if we ask doit to build target B, doit will only check if target B is up-to-date without checking any of the dependencies. To overcome this, we will need to specify \u003Ccode\u003EoutA\u003C\u002Fcode\u003E 4 times — also as file dependency of target B. I see this as a drawback. Both Make and CMake are able to handle such situations correctly.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nDependencies in doit are file-based and expressed as strings. This means that dependencies \u003Ccode\u003E.\u002Fmyfile.txt\u003C\u002Fcode\u003E and \u003Ccode\u003Emyfile.txt\u003C\u002Fcode\u003E are viewed as being different. As I wrote above, I find the way of passing information from target to target (when using python targets) a bit strange. Target has a list of artifacts it is going to produce, but another target can't use it. Instead the python function, which constitutes the target, must return a dictionary, which can be accessed in another target. Let's see it on an example:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"python\"\u003Edef task_preprocess():\n    \"\"\"Preprocess IRIS dataset\"\"\"\n    pickle_file = 'data\u002Fprocessed\u002Fprocessed.pickle'\n    excel_file = 'data\u002Fprocessed\u002Fprocessed.xlsx'\n    return {\n        'file_dep': ['src\u002Fdata\u002Fpreprocess.py'],\n        'targets': [pickle_file, excel_file],\n        'actions': [doit_pypreprocess],\n        'getargs': {'input_file': ('rawdata', 'filename')},\n        'clean': True,\n    }\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nHere the target \u003Ccode\u003Epreprocess\u003C\u002Fcode\u003E depends on \u003Ccode\u003Erawdata\u003C\u002Fcode\u003E. The dependency is provided via \u003Ccode\u003Egetargs\u003C\u002Fcode\u003E property. It says that the argument \u003Ccode\u003Einput_file\u003C\u002Fcode\u003E of function \u003Ccode\u003Edoit_pypreprocess\u003C\u002Fcode\u003E is the output \u003Ccode\u003Efilename\u003C\u002Fcode\u003E of the target \u003Ccode\u003Erawdata\u003C\u002Fcode\u003E. Have a look at the complete example in file \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffralik\u002Fovercome-the-chaos\u002Fblob\u002Fmaster\u002Fdodo.py\"\u003Edodo.py\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nIt may be worth reading \u003Ca href=\"http:\u002F\u002Fpydoit.org\u002Fstories.html\"\u003Ethe success stories\u003C\u002Fa\u003E of using doit. It definitely has nice features like the ability to provide a custom up-to-date target check.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003E\u003Ca name=\"Luigi\"\u003E\u003C\u002Fa\u003ELuigi\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nLuigi stays apart from other tools as it is a system to build complex pipelines. It appeared on my radar after a colleague told me that he tried Make, was never able to use it across Windows\u002FLinux and moved away to Luigi.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nLuigi aims at production-ready systems. It comes with a server, which can be used to visualize your tasks or to get a history of task executions. The server is called a \u003Cem\u003Ecentral schedler\u003C\u002Fem\u003E. A local scheduler is available for debugging purposes.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nLuigi is also different from other systems in a way how tasks are created. Lugi doesn't act on some predefined file (like \u003Ccode\u003Edodo.py\u003C\u002Fcode\u003E, \u003Ccode\u003Epavement.py\u003C\u002Fcode\u003E or makefile). Rather, one has to pass a python module name. So, if we try to use it in the similar way to other tools (place a file with tasks in project's root), it won't work. We have to either install our project or modify environmental variable \u003Ccode\u003EPYTHONPATH\u003C\u002Fcode\u003E by adding the path to the project.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nWhat is great about luigi is the way of specifying dependencies between tasks. Each task is a class. Method \u003Ccode\u003Eoutput\u003C\u002Fcode\u003E tells Luigi where the results of the task will end up. Results can be a single element or a list. Method \u003Ccode\u003Erequires\u003C\u002Fcode\u003E specifies task dependencies (other tasks; although it is possible to make a dependency from itself). And that's it. Whatever is specified as \u003Ccode\u003Eoutput\u003C\u002Fcode\u003E in task A will be passed as an input to task B if task B relies on task A.\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fpost_images\u002Fba2\u002F95c\u002Fbb9\u002Fba295cbb9b744767e709aa7b3a0e358f.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nLuigi doesn't care about file modifications. It cares about file existance. So it is not possible to trigger rebuilds when the source code changes. Luigi doesn't have a built-in \u003Ci\u003Eclean\u003C\u002Fi\u003E functionality.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nLuigi tasks for this project are available in file \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffralik\u002Fovercome-the-chaos\u002Fblob\u002Fmaster\u002Fluigitasks.py\"\u003Eluigitasks.py\u003C\u002Fa\u003E. I run them from the terminal:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"plaintext\"\u003Eluigi --local-scheduler --module luigitasks Exploratory\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\n\u003Ch2\u003E\u003Ca name=\"Comparison\"\u003E\u003C\u002Fa\u003EComparison\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nThe table below summarizes how different systems work in respect to our specific goals.\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"scrollable-table\"\u003E\u003Ctable\u003E\r\n\u003Ctr\u003E\r\n\u003Cth\u003E \u003C\u002Fth\u003E\r\n\u003Cth\u003EDefine target with dependency\u003C\u002Fth\u003E\r\n\u003Cth\u003EIncremental builds\u003C\u002Fth\u003E\r\n\u003Cth\u003EIncremental builds if source code is changed\u003C\u002Fth\u003E\r\n\u003Cth\u003EAbility to figure out which artifacts to remove during \u003Ccode\u003Eclean\u003C\u002Fcode\u003E command\u003C\u002Fth\u003E\r\n\u003C\u002Ftr\u003E\r\n\u003Ctr\u003E\r\n\u003Ctd\u003E\u003Cstrong\u003ECMake\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003C\u002Ftr\u003E\r\n\u003Ctr\u003E\r\n\u003Ctd\u003E\u003Cstrong\u003EPynt\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003C\u002Ftr\u003E\r\n\u003Ctr\u003E\r\n\u003Ctd\u003E\u003Cstrong\u003EPaver\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003C\u002Ftr\u003E\r\n\u003Ctr\u003E\r\n\u003Ctd\u003E\u003Cstrong\u003Edoit\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\r\n\u003Ctd\u003ESomewhat yes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003C\u002Ftr\u003E\r\n\u003Ctr\u003E\r\n\u003Ctd\u003E\u003Cstrong\u003ELuigi\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eyes\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003Ctd\u003Eno\u003C\u002Ftd\u003E\r\n\u003C\u002Ftr\u003E\r\n\u003C\u002Ftable\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"make"},{"titleHtml":"cmake"},{"titleHtml":"python"},{"titleHtml":"pynt"},{"titleHtml":"paver"},{"titleHtml":"pydoit"},{"titleHtml":"luigi"},{"titleHtml":"build tools"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F451962\u002Feec41c344b3ef0376b56feee86419a83\u002F","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F451962\u002Feec41c344b3ef0376b56feee86419a83\u002F?format=vk","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fen\\\u002Fpost\\\u002F451962\\\u002F\"},\"headline\":\"Build tools in machine learning projects, an overview\",\"datePublished\":\"2019-05-20T12:39:38+03:00\",\"dateModified\":\"2019-05-20T23:45:10+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Vadim Frolov\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"I was wondering about machine learning\\\u002Fdata science project structure\\\u002Fworkflow and was reading different opinions on the subject. And when people start to talk...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fen\\\u002Fpost\\\u002F451962\\\u002F#post-content-body\",\"about\":[\"h_machine_learning\",\"h_build_automation\",\"f_develop\"],\"image\":[\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fpost_images\\\u002Faff\\\u002Ffbf\\\u002F656\\\u002Fafffbf6566a6e67ea6427d28d76d7eea.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Foo\\\u002Fza\\\u002Fpj\\\u002Foozapjujvjg_q86ndg6r7c5u36a.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fxh\\\u002Fte\\\u002Fol\\\u002Fxhteolpanywbjxanltb8uxdsoly.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fpost_images\\\u002Fba2\\\u002F95c\\\u002Fbb9\\\u002Fba295cbb9b744767e709aa7b3a0e358f.png\"]}","metaDescription":"I was wondering about machine learning\u002Fdata science project structure\u002Fworkflow and was reading different opinions on the subject. And when people start to talk about workflow they want their workflows...","mainImageUrl":null,"amp":false},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"machine_learning,build_automation"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>

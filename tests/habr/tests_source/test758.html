<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model» / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/post\/451738\/"},"headline":"Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model»","datePublished":"2019-05-14T11:38:04+03:00","dateModified":"2019-05-14T13:43:42+03:00","author":{"@type":"Person","name":"Andre1540"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Рассматриваемая статья. Введение Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связан...","url":"https:\/\/habr.com\/ru\/post\/451738\/#post-content-body","about":["h_machine_learning","f_develop"],"image":["https:\/\/habrastorage.org\/getpro\/habr\/formulas\/ca4\/8ea\/214\/ca48ea214c7d51429daed04bc3b5269e.svg","https:\/\/habrastorage.org\/webt\/59\/ki\/-t\/59ki-torfbo8ufarpy8vlwdalze.png","https:\/\/habrastorage.org\/webt\/wd\/wu\/-b\/wdwu-bbzhgw2jwdcyn_bnxa9h_o.png","https:\/\/habrastorage.org\/getpro\/habr\/formulas\/5a2\/327\/384\/5a232738434707dcfd35ab20cfe59460.svg","https:\/\/habrastorage.org\/webt\/p_\/i7\/dm\/p_i7dmm6gvhc8h9ndzd20hrryye.png","https:\/\/habrastorage.org\/webt\/50\/w6\/bc\/50w6bceiaq61y6ohmehsmqzrrhc.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model»" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model»" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model»" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Рассматриваемая статья.
Введение
Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Рассматриваемая статья.
Введение
Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Рассматриваемая статья.
Введение
Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Рассматриваемая статья.
Введение
Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Рассматриваемая статья.
Введение
Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habr.com/share/publication/451738/2590b70938e2e2b313de55a20a4dadca/" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habr.com/share/publication/451738/2590b70938e2e2b313de55a20a4dadca/" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habr.com/share/publication/451738/2590b70938e2e2b313de55a20a4dadca/" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habr.com/share/publication/451738/2590b70938e2e2b313de55a20a4dadca/" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habr.com/share/publication/451738/2590b70938e2e2b313de55a20a4dadca/" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="451738" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2019-05-14T08:38:04.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/451738/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/post/451738/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habr.com/share/publication/451738/2590b70938e2e2b313de55a20a4dadca/" data-vmid="image:href">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/Andre1540/" title="Andre1540" class="tm-user-info__userpic"><div class="tm-entity-image"><svg height="24" width="24" class="tm-svg-img tm-image-placeholder tm-image-placeholder_blue"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <span class="tm-user-info__user"><a href="/ru/users/Andre1540/" class="tm-user-info__username">
      Andre1540
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2019-05-14T08:38:04.000Z" title="2019-05-14, 11:38">14  мая  2019 в 11:38</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model»</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <div class="tm-article-snippet__labels"><div class="tm-article-snippet__label"><span>
        Из песочницы
      </span></div></div> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41473.pdf">Рассматриваемая статья.</a></p><br/>
<h3 id="vvedenie">Введение</h3><br/>
<p>Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение текстовой информации, даже несвязанной с картинками, позволяет обогатить модель и в некоторой степени решить следующие проблемы: </p><br/>
<ol>
<li>если модель распознавания совершает ошибку, то часто эта ошибка семантически не близка к правильному классу;</li>
<li>нет возможности предсказать объект, который относится к новому классу, который не был представлен в обучающем наборе данных.</li>
</ol><br/>
<p>Предложенный подход предлагает отображать картинки в богатое семантическое пространство, в котором метки более схожих классов находятся ближе к друг другу, чем метки менее похожих классов. Как результат, модель дает меньше семантически далеких от истинного класса предсказаний. Более того, модель, учитывая и визуальную и семантическую близость, может правильно классифицировать изображения, относящиеся к классу, который не был представлен в обучающем наборе данных. </p><a name="habracut"></a><br/>
<h3 id="algoritm-arhitektura">Алгоритм. Архитектура</h3><br/>
<ol>
<li>Предобучаем language model, которая дает хорошие семантически значимые эмбединги. Размерность пространства — n. Далее n будет взято равным 500 или 1000.</li>
<li>Предобучаем visual model, которая хорошо классифицирует объекты на 1000 классов. </li>
<li>Отрезаем последний софтмакс слой от предобученной визуальной модели и добавляем полносвязный слой с 4096 на n нейронов. Полученную модель тренируем для каждого изображения предсказывать эмбединг соответствующий метке изображения.</li>
</ol><br/>
<p>Поясним с помощью отображений. Пусть LM — language model, VM — visual model c отрезанным софтмаксом и добавленным полносвязным слоем, I — image, L — label of image, LM(L) — эмбединг метки в семантическом пространстве. Тогда на третьем шаге мы обучаем VM так, чтобы:</p><br/>
<p></p><p><img src="https://habrastorage.org/getpro/habr/formulas/ca4/8ea/214/ca48ea214c7d51429daed04bc3b5269e.svg" alt="$VM(I) = LM(L)$" data-tex="display"/></p><br/>
<p>Архитектура:</p><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/59/ki/-t/59ki-torfbo8ufarpy8vlwdalze.png"/><br/>
<h3 id="yazykovaya-model">Языковая модель</h3><br/>
<p>Для обучения языковой модели использовалась skip-gram модель, корпус из 5.4 миллиарда слов взятый с wikipedia.org. Модель использовала иерархичный софтмакс слой для предсказания смежных понятий, окно — 20 слов, количество проходов по корпусу — 1. Экспериментально установлено, что размер эмбединга лучше брать 500-1000. </p><br/>
<p>Картинка расположения классов в пространстве показывает, что модель выучила качественную и богатую семантическую структуру. Например, для определенного вида акул в полученном семантическом пространстве 9 ближайших соседей — другие 9 типов акул.</p><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/wd/wu/-b/wdwu-bbzhgw2jwdcyn_bnxa9h_o.png"/><br/>
<h3 id="vizualnaya-model">Визуальная модель</h3><br/>
<p>В качестве визуальной модели была взята архитектура победившая на соревновании ILSVRC 2012 года. В ней удалили софтмакс и добавили полносвязный слой, чтобы получить на выходе нужный размер эмбединга.</p><br/>
<h3 id="funkciya-poter">Функция потерь</h3><br/>
<p>Оказалось, что выбор функции потерь — важен. Использовалась комбинация cosine similarity и hinge rank loss. Функция потерь пощряла бОльшее скалярное произведение между вектором результата визуальной сети и соответствующего ембединга метки и штрафовала за большое скалярное произведение между результатом визуальной сети и ембедингами случайных возможных меток изображений. Количество произвольных случайных меток было не фиксированным, а ограничивалось условием при котором, сумма скалярных произведений с ложными метками становилась больше чем скалярное произведение с верной меткой минус фиксированный марджин (константа равная 0.1). Конечно, все вектора были предварительно нормированы.</p><br/>
<p></p><p><img src="https://habrastorage.org/getpro/habr/formulas/5a2/327/384/5a232738434707dcfd35ab20cfe59460.svg" alt="$loss(I, L) = \sum_{j}{max[0, margin - (L, VM(I)) + (wrongL_j, VM(I))]}$" data-tex="display"/></p><br/>
<h3 id="process-trenirovki">Процесс тренировки</h3><br/>
<p>В начале тренировался только последний добавленный полносвязный слой, оставшаяся часть сети не обновляла веса. При этом использовался метод оптимизации SGD. Затем размораживалась вся визуальная сеть и тренировалась с использование оптимизатора Adagrad, чтобы во время back propagation на разных слоях сети градиенты масштабировались правильно.</p><br/>
<h3 id="predskazanie">Предсказание</h3><br/>
<p>Во время предсказания, по изображению с помощью визуальной сети мы получаем некоторый вектор в нашем семантическом пространстве. Далее, мы находим ближайших соседей, то есть некоторые возможные метки и специальным образом отображаем их обратно в ImageNet synsets для скоринга. Процедура последнего отображения не так проста, так как метки в ImageNet — набор синонимов, а не одна метка. Если читателю интересно узнать детали, рекомендую оригинальную статью (аппендикс 2).</p><br/>
<h2 id="rezultaty">Результаты</h2><br/>
<p>Результат работы модели DEVISE сравнивался с двумя моделями:</p><br/>
<ol>
<li>Softmax baseline model – a state-of-the-art vision model (SOTA — на момент публикации)</li>
<li>Random embedding model — версия описанной модели DEVISE, где ембединги — не выучены языковой моделью, а инициализируются произвольно.</li>
</ol><br/>
<p>Для оценки качества использовались “flat” hit@k metrics и hierarchical precision@k metric. Метрика “flat” hit@k — процент тестовых изображений, для которых правильная метка присутствует среди первых k предсказанных вариантов. Метрика hierarchical precision@k использовалась для оценки качества семантического соответствия. Эта метрика основывалась на иерархии меток в ImageNet. Для каждой истиной метки и фиксированного k определялся набор<br/>
семантически верных меток — ground truth list. Получая предсказание (ближайшие соседи) находился процент пересечения с ground truth list.</p><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/p_/i7/dm/p_i7dmm6gvhc8h9ndzd20hrryye.png"/><br/>
<p>Авторы ожидали, что софтмакс модель должна демонстрировать наилучшие результаты на flat metric из-за того, что она минимизирует cross-entropy loss, что очень хорошо подходит для “flat” hit@k metrics. Авторы были удивлены, как близко модель DEVISE подходит к софтмакс модели, достигает паритета на больших k и даже обгоняет при k=20.</p><br/>
<p>На иерархической метрике модель DEVISE показывает себя во всей красе и обгоняет софтмаксовский бейзлан на 3% для k=5 и на 7% для k=20.</p><br/>
<h3 id="zero-shot-learning">Zero-Shot Learning</h3><br/>
<p>Особенным преимуществом DEVISE модели является способность давать адекватное предсказание для изображений, меток которых сеть никогда не видела при тренировке. Например, сеть во время тренировки видела изображения помеченные tiger shark, bull shark, and blue shark и никогда не встречала метку shark. Поскольку языковая модель имеет представление для shark в семантическом пространстве и оно близко к эмбедингам разных видов shark, то модель с большой долей вероятности даст адекватное предсказание. Это называется способностью обобщения — генерализации.</p><br/>
<p>Продемонстрируем несколько примеров Zero-Shot предсказаний:</p><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/50/w6/bc/50w6bceiaq61y6ohmehsmqzrrhc.png"/><br/>
<p>Заметим, что модель DEVISE даже в своих ошибочных предположениях ближе к правильному ответу чем ошибочные предположения софтмакс модели.</p><br/>
<p>Итак, представленная модель, совсем немного проигрывает софтмакс бейзлайну на flat metrics, но значительно выигрывает на hierarchical precision@k metric. Модель имеет способность обобщать, выдавая адекватные предсказания для изображений, меток которых сеть не встречала (zero-shot learning).</p><br/>
<p>Описанный подход может быть легко имплементирован, так как основывается на двух предобученных моделях — языковой и визуальной.</p></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BDeViSE%5D" class="tm-tags-list__link">DeViSE</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BDeep%5D" class="tm-tags-list__link">Deep</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BVisual-Semantic%5D" class="tm-tags-list__link">Visual-Semantic</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BEmbedding%5D" class="tm-tags-list__link">Embedding</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BModel%5D" class="tm-tags-list__link">Model</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 7: ↑7 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 7: ↑7 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+7</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">865</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    11
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/Andre1540/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><svg class="tm-svg-img tm-image-placeholder tm-image-placeholder_blue"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <div class="tm-user-card__meta"><div title=" 5 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    5
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">0</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><!----> <a href="/ru/users/Andre1540/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @Andre1540
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Пользователь</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/451738/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментировать 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/451738/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/451738/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"451738":{"id":"451738","timePublished":"2019-05-14T08:38:04+00:00","isCorporative":false,"lang":"ru","titleHtml":"Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model»","leadData":{"textHtml":"\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fstatic.googleusercontent.com\u002Fmedia\u002Fresearch.google.com\u002Fen\u002F\u002Fpubs\u002Farchive\u002F41473.pdf\"\u003EРассматриваемая статья.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cbr\u003E\r\n\u003Ch3 id=\"vvedenie\"\u003EВведение\u003C\u002Fh3\u003E\u003Cbr\u003E\r\n\u003Cp\u003EСовременные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение текстовой информации, даже несвязанной с картинками, позволяет обогатить модель и в некоторой степени решить следующие проблемы: \u003C\u002Fp\u003E\u003Cbr\u003E\r\n\u003Col\u003E\r\n\u003Cli\u003Eесли модель распознавания совершает ошибку, то часто эта ошибка семантически не близка к правильному классу;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eнет возможности предсказать объект, который относится к новому классу, который не был представлен в обучающем наборе данных.\u003C\u002Fli\u003E\r\n\u003C\u002Fol\u003E\u003Cbr\u003E\r\n\u003Cp\u003EПредложенный подход предлагает отображать картинки в богатое семантическое пространство, в котором метки более схожих классов находятся ближе к друг другу, чем метки менее похожих классов. Как результат, модель дает меньше семантически далеких от истинного класса предсказаний. Более того, модель, учитывая и визуальную и семантическую близость, может правильно классифицировать изображения, относящиеся к классу, который не был представлен в обучающем наборе данных. \u003C\u002Fp\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше →","image":null},"editorVersion":"1.0","postType":"article","postLabels":[{"type":"sandbox","data":null}],"author":{"scoreStats":{"score":5,"votesCount":5},"rating":0,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"2050981","alias":"Andre1540","fullname":null,"avatarUrl":null,"speciality":null},"statistics":{"commentsCount":0,"favoritesCount":11,"readingCount":865,"score":7,"votesCount":7},"hubs":[{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fstatic.googleusercontent.com\u002Fmedia\u002Fresearch.google.com\u002Fen\u002F\u002Fpubs\u002Farchive\u002F41473.pdf\"\u003EРассматриваемая статья.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"vvedenie\"\u003EВведение\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EСовременные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение текстовой информации, даже несвязанной с картинками, позволяет обогатить модель и в некоторой степени решить следующие проблемы: \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Col\u003E\r\n\u003Cli\u003Eесли модель распознавания совершает ошибку, то часто эта ошибка семантически не близка к правильному классу;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eнет возможности предсказать объект, который относится к новому классу, который не был представлен в обучающем наборе данных.\u003C\u002Fli\u003E\r\n\u003C\u002Fol\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПредложенный подход предлагает отображать картинки в богатое семантическое пространство, в котором метки более схожих классов находятся ближе к друг другу, чем метки менее похожих классов. Как результат, модель дает меньше семантически далеких от истинного класса предсказаний. Более того, модель, учитывая и визуальную и семантическую близость, может правильно классифицировать изображения, относящиеся к классу, который не был представлен в обучающем наборе данных. \u003C\u002Fp\u003E\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"algoritm-arhitektura\"\u003EАлгоритм. Архитектура\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Col\u003E\r\n\u003Cli\u003EПредобучаем language model, которая дает хорошие семантически значимые эмбединги. Размерность пространства — n. Далее n будет взято равным 500 или 1000.\u003C\u002Fli\u003E\r\n\u003Cli\u003EПредобучаем visual model, которая хорошо классифицирует объекты на 1000 классов.\u2028\u003C\u002Fli\u003E\r\n\u003Cli\u003EОтрезаем последний софтмакс слой от предобученной визуальной модели и добавляем полносвязный слой с 4096 на n нейронов. Полученную модель тренируем для каждого изображения предсказывать эмбединг соответствующий метке изображения.\u003C\u002Fli\u003E\r\n\u003C\u002Fol\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПоясним с помощью отображений. Пусть LM — language model, VM — visual model c отрезанным софтмаксом и добавленным полносвязным слоем, I — image, L — label of image, LM(L) — эмбединг метки в семантическом пространстве. Тогда на третьем шаге мы обучаем VM так, чтобы:\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fformulas\u002Fca4\u002F8ea\u002F214\u002Fca48ea214c7d51429daed04bc3b5269e.svg\" alt=\"$VM(I) = LM(L)$\" data-tex=\"display\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EАрхитектура:\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F59\u002Fki\u002F-t\u002F59ki-torfbo8ufarpy8vlwdalze.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"yazykovaya-model\"\u003EЯзыковая модель\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EДля обучения языковой модели использовалась skip-gram модель, корпус из 5.4 миллиарда слов взятый с wikipedia.org. Модель использовала иерархичный софтмакс слой для предсказания смежных понятий, окно — 20 слов, количество проходов по корпусу — 1. Экспериментально установлено, что размер эмбединга лучше брать 500-1000. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКартинка расположения классов в пространстве показывает, что модель выучила качественную и богатую семантическую структуру. Например, для определенного вида акул в полученном семантическом пространстве 9 ближайших соседей — другие 9 типов акул.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fwd\u002Fwu\u002F-b\u002Fwdwu-bbzhgw2jwdcyn_bnxa9h_o.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"vizualnaya-model\"\u003EВизуальная модель\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВ качестве визуальной модели была взята архитектура победившая на соревновании ILSVRC 2012 года. В ней удалили софтмакс и добавили полносвязный слой, чтобы получить на выходе нужный размер эмбединга.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"funkciya-poter\"\u003EФункция потерь\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EОказалось, что выбор функции потерь — важен. Использовалась комбинация cosine similarity и hinge rank loss. Функция потерь пощряла бОльшее скалярное произведение между вектором результата визуальной сети и соответствующего ембединга метки и штрафовала за большое скалярное произведение между результатом визуальной сети и ембедингами случайных возможных меток изображений. Количество произвольных случайных меток было не фиксированным, а ограничивалось условием при котором, сумма скалярных произведений с ложными метками становилась больше чем скалярное произведение с верной меткой минус фиксированный марджин (константа равная 0.1). Конечно, все вектора были предварительно нормированы.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fformulas\u002F5a2\u002F327\u002F384\u002F5a232738434707dcfd35ab20cfe59460.svg\" alt=\"$loss(I, L) = \\sum_{j}{max[0, margin - (L, VM(I)) + (wrongL_j, VM(I))]}$\" data-tex=\"display\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"process-trenirovki\"\u003EПроцесс тренировки\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВ начале тренировался только последний добавленный полносвязный слой, оставшаяся часть сети не обновляла веса. При этом использовался метод оптимизации SGD. Затем размораживалась вся визуальная сеть и тренировалась с использование оптимизатора Adagrad, чтобы во время back propagation на разных слоях сети градиенты масштабировались правильно.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"predskazanie\"\u003EПредсказание\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВо время предсказания, по изображению с помощью визуальной сети мы получаем некоторый вектор в нашем семантическом пространстве. Далее, мы находим ближайших соседей, то есть некоторые возможные метки и специальным образом отображаем их обратно в ImageNet synsets для скоринга. Процедура последнего отображения не так проста, так как метки в ImageNet — набор синонимов, а не одна метка. Если читателю интересно узнать детали, рекомендую оригинальную статью (аппендикс 2).\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch2 id=\"rezultaty\"\u003EРезультаты\u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EРезультат работы модели DEVISE сравнивался с двумя моделями:\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Col\u003E\r\n\u003Cli\u003ESoftmax baseline model – a state-of-the-art vision model (SOTA — на момент публикации)\u003C\u002Fli\u003E\r\n\u003Cli\u003ERandom embedding model — версия описанной модели DEVISE, где ембединги — не выучены языковой моделью, а инициализируются произвольно.\u003C\u002Fli\u003E\r\n\u003C\u002Fol\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EДля оценки качества использовались “flat” hit@k metrics и hierarchical precision@k metric. Метрика “flat” hit@k — процент тестовых изображений, для которых правильная метка присутствует среди первых k предсказанных вариантов. Метрика hierarchical precision@k использовалась для оценки качества семантического соответствия. Эта метрика основывалась на иерархии меток в ImageNet. Для каждой истиной метки и фиксированного k определялся набор\u003Cbr\u002F\u003E\r\nсемантически верных меток — ground truth list. Получая предсказание (ближайшие соседи) находился процент пересечения с ground truth list.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fp_\u002Fi7\u002Fdm\u002Fp_i7dmm6gvhc8h9ndzd20hrryye.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EАвторы ожидали, что софтмакс модель должна демонстрировать наилучшие результаты на flat metric из-за того, что она минимизирует cross-entropy loss, что очень хорошо подходит для “flat” hit@k metrics. Авторы были удивлены, как близко модель DEVISE подходит к софтмакс модели, достигает паритета на больших k и даже обгоняет при k=20.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EНа иерархической метрике модель DEVISE показывает себя во всей красе и обгоняет софтмаксовский бейзлан на 3% для k=5 и на 7% для k=20.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3 id=\"zero-shot-learning\"\u003EZero-Shot Learning\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EОсобенным преимуществом DEVISE модели является способность давать адекватное предсказание для изображений, меток которых сеть никогда не видела при тренировке. Например, сеть во время тренировки видела изображения помеченные tiger shark, bull shark, and blue shark и никогда не встречала метку shark. Поскольку языковая модель имеет представление для shark в семантическом пространстве и оно близко к эмбедингам разных видов shark, то модель с большой долей вероятности даст адекватное предсказание. Это называется способностью обобщения — генерализации.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПродемонстрируем несколько примеров Zero-Shot предсказаний:\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F50\u002Fw6\u002Fbc\u002F50w6bceiaq61y6ohmehsmqzrrhc.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EЗаметим, что модель DEVISE даже в своих ошибочных предположениях ближе к правильному ответу чем ошибочные предположения софтмакс модели.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИтак, представленная модель, совсем немного проигрывает софтмакс бейзлайну на flat metrics, но значительно выигрывает на hierarchical precision@k metric. Модель имеет способность обобщать, выдавая адекватные предсказания для изображений, меток которых сеть не встречала (zero-shot learning).\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EОписанный подход может быть легко имплементирован, так как основывается на двух предобученных моделях — языковой и визуальной.\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"DeViSE"},{"titleHtml":"Deep"},{"titleHtml":"Visual-Semantic"},{"titleHtml":"Embedding"},{"titleHtml":"Model"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F451738\u002F2590b70938e2e2b313de55a20a4dadca\u002F","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F451738\u002F2590b70938e2e2b313de55a20a4dadca\u002F?format=vk","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F451738\\\u002F\"},\"headline\":\"Краткий разбор статьи «DeViSE: A Deep Visual-Semantic Embedding Model»\",\"datePublished\":\"2019-05-14T11:38:04+03:00\",\"dateModified\":\"2019-05-14T13:43:42+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Andre1540\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Рассматриваемая статья. Введение Современные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связан...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F451738\\\u002F#post-content-body\",\"about\":[\"h_machine_learning\",\"f_develop\"],\"image\":[\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fformulas\\\u002Fca4\\\u002F8ea\\\u002F214\\\u002Fca48ea214c7d51429daed04bc3b5269e.svg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F59\\\u002Fki\\\u002F-t\\\u002F59ki-torfbo8ufarpy8vlwdalze.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fwd\\\u002Fwu\\\u002F-b\\\u002Fwdwu-bbzhgw2jwdcyn_bnxa9h_o.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fformulas\\\u002F5a2\\\u002F327\\\u002F384\\\u002F5a232738434707dcfd35ab20cfe59460.svg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fp_\\\u002Fi7\\\u002Fdm\\\u002Fp_i7dmm6gvhc8h9ndzd20hrryye.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F50\\\u002Fw6\\\u002Fbc\\\u002F50w6bceiaq61y6ohmehsmqzrrhc.png\"]}","metaDescription":"Рассматриваемая статья.\r\nВведение\r\nСовременные распознавательные системы лимитированы классифицировать на относительно не большое количество семантически не связанных между собой классов. Привлечение...","mainImageUrl":null,"amp":false},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"machine_learning"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>

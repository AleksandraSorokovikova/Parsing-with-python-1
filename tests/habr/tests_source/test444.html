<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>End2End-подход к пониманию разговорной речи / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/company\/ru_mts\/blog\/451008\/"},"headline":"End2End-подход к пониманию разговорной речи","datePublished":"2019-05-08T14:58:01+03:00","dateModified":"2019-05-08T15:45:58+03:00","author":{"@type":"Person","name":"info_habr"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимани...","url":"https:\/\/habr.com\/ru\/company\/ru_mts\/blog\/451008\/#post-content-body","about":["c_ru_mts","h_algorithms","h_machine_learning","h_artificial_intelligence","h_itcompanies","f_develop","f_popsci"],"image":["https:\/\/habrastorage.org\/webt\/4f\/zx\/o3\/4fzxo3p37pnl9kprkwk1trmwxd4.png","https:\/\/habrastorage.org\/webt\/sl\/s9\/a1\/sls9a1uzwmia7h523tecvgssiec.png","https:\/\/habrastorage.org\/webt\/nf\/an\/6l\/nfan6l3vzzjsl_r4iq9_3x491rk.png","https:\/\/habrastorage.org\/webt\/u0\/pz\/y8\/u0pzy8cvkx_texgnjfzun-keavu.png","https:\/\/habrastorage.org\/webt\/yi\/34\/tx\/yi34txzqvgevrvoauj4stho32im.png","https:\/\/habrastorage.org\/webt\/34\/kl\/m2\/34klm26dj3vk5sd9kdcxckkenii.png","https:\/\/habrastorage.org\/webt\/jz\/kn\/-f\/jzkn-frploycnewpluip2kgoqb8.png","https:\/\/habrastorage.org\/webt\/ym\/kz\/l3\/ymkzl3t_nh892ohttlu84sjg98i.png","https:\/\/habrastorage.org\/webt\/8l\/-q\/pj\/8l-qpjo3dccdzmqh5a-fspmveiq.png","https:\/\/habrastorage.org\/webt\/fr\/az\/np\/fraznpocvjmklcjjmau4i9v9ago.png","https:\/\/habrastorage.org\/webt\/pa\/24\/xr\/pa24xr-aaep-mqo7bzd3loksve4.png","https:\/\/habrastorage.org\/webt\/cj\/bb\/of\/cjbbofaddfuhufwqk3brhr2-l04.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="End2End-подход к пониманию разговорной речи" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="End2End-подход к пониманию разговорной речи" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="End2End-подход к пониманию разговорной речи" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент,..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент,..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент,..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент,..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент,..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habr.com/share/publication/451008/2479b560db4728453d90d9d179a650d7/" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habr.com/share/publication/451008/2479b560db4728453d90d9d179a650d7/" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habr.com/share/publication/451008/2479b560db4728453d90d9d179a650d7/" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habr.com/share/publication/451008/2479b560db4728453d90d9d179a650d7/" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habr.com/share/publication/451008/2479b560db4728453d90d9d179a650d7/" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="451008" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2019-05-08T11:58:01.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/451008/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/company/ru_mts/blog/451008/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habr.com/share/publication/451008/2479b560db4728453d90d9d179a650d7/" data-vmid="image:href"><link data-vue-meta="ssr" rel="amphtml" href="https://habr.com/ru/amp/post/451008/">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" companyName="ru_mts" data-async-called="true" class="tm-page"><div class="tm-page-width"><div class="tm-page__header"><!----></div> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"><div class="tm-company-card tm-company-article__company-card"><div class="tm-company-card__info"><div class="tm-company-card__header"><a href="/ru/company/ru_mts/profile/" class="tm-company-card__avatar"><div class="tm-entity-image"><img alt="" height="48" src="//habrastorage.org/getpro/habr/company/e0b/0e6/247/e0b0e62479e2f247215d4497c4dd88af.png" width="48" class="tm-entity-image__pic"></div></a> <!----> <div class="tm-rating tm-company-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">130.5</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div> <div class="tm-company-card__info"><a href="/ru/company/ru_mts/profile/" class="tm-company-card__name">
        МТС
      </a> <div class="tm-company-card__description"></div></div></div> <div class="tm-company-card__buttons"><!----> <!----></div></div> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/info_habr/" title="info_habr" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/66c/94f/0c0/66c94f0c0da486268bb09c00f0b023e3.png" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/info_habr/" class="tm-user-info__username">
      info_habr
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2019-05-08T11:58:01.000Z" title="2019-05-08, 14:58">8  мая  2019 в 14:58</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>End2End-подход к пониманию разговорной речи</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/company/ru_mts/blog/" class="tm-article-snippet__hubs-item-link router-link-active"><span>Блог компании МТС</span> <!----></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/algorithms/" class="tm-article-snippet__hubs-item-link"><span>Алгоритмы</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/artificial_intelligence/" class="tm-article-snippet__hubs-item-link"><span>Искусственный интеллект</span> <!----></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/itcompanies/" class="tm-article-snippet__hubs-item-link"><span>IT-компании</span> <!----></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml"><i>Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент, отвечающий за некую бизнес-логику) и End2End-подход, который предполагает четыре модели реализации: прямую, совместную, многоступенчатую и многозадачную. Рассмотрим все плюсы и минусы этих подходов, в том числе на основе экспериментов компании Google, и подробно разберем, почему End2End-подход решает проблемы классического подхода.<br/>
</i><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/4f/zx/o3/4fzxo3p37pnl9kprkwk1trmwxd4.png"/><a name="habracut"></a><br/>
<br/>
Передаем слово ведущему разработчику центра AI МТС Никите Семенову.<br/>
<br/>
Привет! В качестве предисловия хочу процитировать всем известных ученых Яна Лекуна, Иошуа Бенджио и Джеффри Хинтона — это три пионера искусственного интеллекта, которые недавно получили одну из самых престижных премий в области информационных технологий — премию Тьюринга. В одном из выпусков журнала Nature в 2015 году они выпустили очень интересную статью «Deep learning», в которой была занимательная фраза: «Deep learning came with the promise of its capability to deal with raw signals without the need for hand-crafted features». Ее трудно корректно перевести, но смысл примерно такой: «Глубокое обучение пришло с обещанием возможности справляться с сырыми сигналами без необходимости ручного создания признаков». На мой взгляд, для разработчиков это главный мотиватор из всех существующих. <br/>
<br/>
<h4>Классический подход</h4><br/>
 Итак, начнем с классического подхода. Когда мы говорим про понимание разговорной речи машиной, мы подразумеваем, что у нас есть некий человек, который хочет управлять какими-то сервисами с помощью своего голоса или испытывает потребность в том, чтобы какая-то система отвечала на его голосовые команды некой логикой. <br/>
<br/>
Как решается такая задача? В классическом варианте используется система, которая, как было сказано выше, состоит из трех крупных компонентов: компонента распознавания речи, компонента понимания естественного языка и компонента, отвечающего за некую бизнес-логику. Понятно, что вначале пользователь создает некий звуковой сигнал, который попадает на компонент распознавания речи и превращается из звука в текст. Затем текст попадает в компонент понимания естественного языка, откуда вытаскивается некая семантическая структура, которая необходима для компонента, отвечающего за бизнес-логику. <br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/sl/s9/a1/sls9a1uzwmia7h523tecvgssiec.png"/><br/>
<br/>
  Что из себя представляет семантическая структура? Это некое обобщение/агрегация нескольких задач в одну — для удобства понимания. Структура включает в себя три важных части: классификацию домена (некое определение тематики), классификацию интента (понимание, а что собственно нужно сделать) и выделение именованных сущностей для заполнения карточек, которые необходимы для конкретных бизнес-задач на следующем этапе.  Чтобы понять, что такое семантическая структура, можно рассмотреть простой пример, который чаще всего приводит компания Google. У нас имеется простой запрос: «Пожалуйста, проиграй какую-то песню какого-то артиста». <br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/nf/an/6l/nfan6l3vzzjsl_r4iq9_3x491rk.png"/><br/>
<br/>
Домен и тематика в этом запросе — музыка; интент — проиграй песню; атрибуты карточки «проиграй песню» — что за песня, какой артист. Такая структура — результат понимания естественного языка. <br/>
<br/>
Если говорить про решение комплексной и многоэтапной задачи понимание разговорной речи, то она, как я уже сказал, состоит из двух этапов: первый — распознавание речи, второй — понимание естественного языка. Классический подход подразумевает полное разделение этих этапов. В качестве первого шага у нас есть некая модель, которая на входе получает акустический сигнал, и на выходе, используя языковую и акустические модели и лексикон, определяет наиболее вероятную словесную гипотезу из этого акустического сигнала. Это полностью вероятностная история — ее можно разложить по известной формуле Байеса и получить формулу, которая позволяет записать функцию правдоподобия выборки и воспользоваться методом максимального правдоподобия. У нас есть условная вероятность сигнала Х при условии словесной последовательности W, которая умножается на вероятность этой словесной последовательности.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/u0/pz/y8/u0pzy8cvkx_texgnjfzun-keavu.png"/><br/>
<br/>
Первый этап мы прошли — получили из звукового сигнала некую словесную гипотезу. Дальше вступает в ход второй компонент, который берет эту самую словесную гипотезу и пытается из нее вытащить семантическую структуру, описанную нами выше. <br/>
<br/>
У нас есть вероятность семантической структуры S при условии словесной последовательности W на входе.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/yi/34/tx/yi34txzqvgevrvoauj4stho32im.png"/><br/>
<br/>
Чем плох классической подход, состоящий из двух этих элементов/шагов, которые обучаются раздельно (т.е. мы сначала обучаем модель первого элемента, а затем модель второго)? <br/>
<br/>
<ul>
<li>Компонент понимания естественного языка работает с высокоуровневыми словесными гипотезами, которые генерирует ASR. Это большая проблема, потому что первый компонент (сам ASR) работает с низкоуровневыми сырыми данными и генерирует высокоуровневую словесную гипотезу, а второй компонент берет на вход уже гипотезу — не сырые данные из первоисточника, а гипотезу, которую дает первая модель — и строит свою гипотезу над гипотезой первого этапа. Это довольно проблематичная история, потому что она становится слишком «условной».</li>
<li>Следующая проблема: мы никак не можем построить связь между важностью слов, которые необходимы для построения той самой семантической структуры, и тем, чему отдает предпочтение первый компонент, строя свою словесную гипотезу. То есть если перефразировать, у нас получается, что гипотеза уже построена. Она строится на основе трех компонентов, как я уже сказал: акустическая часть (то, что пришло на вход и как-то моделируется), языковая часть (полностью моделирует какие-нибудь языковые энграммы — вероятность речи) и лексикон (произношение слов). Это три большие части, которые нужно совместить и найти в них какую-то гипотезу. Но нет возможности влиять на выбор той самой гипотезы так, чтобы эта гипотеза была важна следующему этапу (что в принципе заключается в пункте, что они обучаются полностью раздельно и никак друг на друга не влияют). </li>
</ul><br/>
<h4>End2End-подход</h4><br/>
Мы поняли, что такое классический подход, какие у него есть проблемы. Попробуем решить эти проблемы при помощи End2End-подхода.   <br/>
<br/>
Под End2End мы подразумеваем модель, которая соединит различные компоненты в единый компонент. Моделировать мы будем с помощью моделей, которые состоят из архитектуры encoder-decoder, содержащие модули внимание (attention). Такие архитектуры часто используются в задачах распознавания речи и в задачах, связанных с обработкой естественного языка, в частности, машинного перевода. <br/>
<br/>
Можно выделить четыре варианта реализации таких подходов, которые могли бы решать поставленную перед нами проблему классического подхода: это прямая, совместная, многоступенчатая и многозадачная модели.<br/>
<br/>
<h4>Прямая модель</h4><br/>
Прямая модель берет на вход низкоуровневые сырые признаки, т.е. низкоуровневый аудиосигнал, а на выходе мы сразу получаем семантическую структуру. То есть у нас получается один модуль — вход первого модуля из классического подхода и выход второго модуля из того же классического подхода. Просто такой «черный ящик». Отсюда возникают некоторые плюсы и некоторые минусы. Модель не учится полностью транскрибировать входной сигнал — это явный плюс, потому что нам не нужно собирать большую-большую разметку, не нужно собирать много аудиосигнала, а потом отдавать его ассесорам на разметку. Нам лишь нужен этот аудиосигнал и соответствующая ему семантическая структура. И все. Это во много раз снижает трудозатраты на разметку данных. Наверное, самый большой минус такого подхода в том, что задача слишком сложная для такого «черного ящика», который пытается решить сразу, условно, две задачи. Сначала внутри себя он пытается построить некую транскрипцию, а потом из этой транскрипции выявить ту самую семантическую структуру. Тут встает довольно сложная задача — научиться игнорировать части транскрипции. А это очень сложно. Этот фактор является довольно большим и колоссальным минусом такого подхода. <br/>
<br/>
  Если говорить про вероятности, то данной моделью решается задача поиска наиболее вероятной семантической структуры S из акустического сигнала X с параметрами модели θ. <br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/34/kl/m2/34klm26dj3vk5sd9kdcxckkenii.png"/><br/>
<br/>
<h4>Совместная модель</h4><br/>
Какая существует альтернатива? Это совместная модель. То есть какая-то модель очень похожая на прямую, но за одним исключением: выход у нас уже состоит из словесных последовательностей и к ним просто конкатенируется семантическая структура. То есть у нас на входе есть звуковой сигнал и нейросетевая модель, которая на выходе уже дает одновременно и словесную транскрипцию, и семантическую структуру.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/jz/kn/-f/jzkn-frploycnewpluip2kgoqb8.png"/><br/>
<br/>
Из плюсов: у нас сохраняется простой энкодер, простой декодер. Облегчается обучение, потому что модель не пытается решить сразу две задачи, как в случае прямой модели. Еще из плюсов можно отметить, что все-таки присутствует вот эта зависимость семантической структуры от низкоуровневых звуковых признаков. Потому что опять-таки один энкодер, один декодер. И, соответственно, еще из плюсов можно отметить, что присутствует зависимость в предсказании этой самой семантической структуры и ее влиянии непосредственно на саму транскрипцию — что нас не устраивало в классическом подходе.<br/>
<br/>
Опять-таки нам надо найти наиболее вероятную последовательность слов W и соответствующие им семантические структуры S из акустического сигнала X с параметрами θ. <br/>
<br/>
<h4>Многозадачная модель</h4><br/>
Следующий подход — это многозадачная модель. Опять-таки энкодер-декодер подход, но за одним исключением. <br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/ym/kz/l3/ymkzl3t_nh892ohttlu84sjg98i.png"/><br/>
<br/>
На каждую задачу, то есть на создание словесной последовательности, на создание семантической структуры у нас свой декодер, использующий одно общее скрытое представление, которое генерирует единый энкодер. Очень известный трюк в машинном обучении, очень часто используется в работах. Решение сразу двух неодинаковых задач помогает намного лучше искать зависимости в исходных данных. И как следствие этого — лучшая обобщающая способность, так как выбирается оптимальный параметр сразу для нескольких задач. Такой подход более всего подходит для задач с меньшим количеством данных. И декодеры используют одно скрытое векторное пространство, в которое создает их энкодер. <br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/8l/-q/pj/8l-qpjo3dccdzmqh5a-fspmveiq.png"/><br/>
<br/>
Важно отметить, что уже в вероятности появляется зависимость от параметров моделей энкодера и декодера. И параметры эти важные.<br/>
<br/>
<h4>Многоступенчатая модель</h4><br/>
Перейдем, на мой взгляд, к самому интересному подходу: многоступенчатой модели. Если очень внимательно посмотреть, можно увидеть, что на самом деле это тот же самый двухкомпонентный классический подход за одним только исключением. <br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/fr/az/np/fraznpocvjmklcjjmau4i9v9ago.png"/><br/>
<br/>
Тут существует возможность установить связь между модулями и сделать их одномодульными. Поэтому семантическая структура считается условно зависимой от транскрипции. Есть два варианта работы с этой моделью. Мы можем обучать по отдельности два эти мини-блока: первый и второй энкодер-декодер. Или совместить их и обучать одновременно обе задачи.<br/>
<br/>
В первом случае параметры для двух задач не связаны (мы можем обучать, используя разные данные). Допустим, у нас есть большой корпус звука и соответствующие ему словесные последовательности и транскрипции. Мы «загоняем» их, обучаем только первую часть. Получаем в хорошем моделировании транскрипции. Потом берем вторую часть, обучаем на другом корпусе. Соединяем и получаем решение, которое в таком подходе на 100% соответствует классическому подходу, потому что мы отдельно взяли и обучили первую часть и отдельно — вторую. А дальше мы обучаем соединенную модель на корпусе, который уже содержит триады данных: звуковой сигнал, соответствующая ему транскрипция и соответствующая ей семантическая структура. Если у нас есть такой корпус, мы можем дообучить обученную по отдельности на больших корпусах модель на нашу конкретную небольшую задачку и получить вот таким вот хитрым способом максимальный выигрыш по точности. Такой подход нам позволяет учитывать важность разных частей транскрипции и их влияние на предсказание семантической структуры с помощью <i>учета ошибки</i> второго этапа в первом. <br/>
<br/>
Важно отметить, что итоговая задача очень похожа на классический подход за одним только большим отличием: второй член нашей функции — логарифм вероятности семантической структуры — при условии входного акустического сигнала Х зависит так же еще от параметров <i>модели первого этапа</i>. <br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/pa/24/xr/pa24xr-aaep-mqo7bzd3loksve4.png"/><br/>
<br/>
Здесь также важно отметить, что второй компонент зависит от параметров первой и второй модели.<br/>
<br/>
<h4>Методика оценки точности подходов</h4><br/>
Теперь стоит определиться с методикой оценки точности. Как, собственно, эту точность мерить, чтобы учитывать особенности, которые нас не устраивают в классическом подходе? Существуют классические метки для этих раздельных задач. Для оценки компонентов распознавания речи мы можем взять классическую метрику WER. Это Word Error Rate. Считаем по не очень сложной формуле количество вставок, замен, перестановок слова и делим их на количество всех слов. И получаем некую оценочную характеристику качества нашего распознавания. Для семантической структуры покомпонентно мы можем просто считать F1 score. Это тоже некая классическая метрика для задачи классификации. Тут все плюс-минус понятно. Есть полнота, есть точность. И это просто гармоническое среднее между ними. <br/>
<br/>
Но возникает вопрос, как измерять точность, когда входная транскрипция и выходной аргумент не совпадают или когда выходные данные являются аудиоданными. Компанией Google была предложена метрика, которая будет учитывать важность предсказания первого компонента распознавания речи путем оценки влияния этого самого распознавания на непосредственно второй компонент. Они назвали ее Arg WER, то есть это взвешивание WER по сущностям семантической структуры. <br/>
<br/>
Возьмем запрос: «Поставь будильник на 5 часов». Данная семантическая структура содержит такой аргумент, как «пять часов», аргумент типа «date time». Важно понимать, если компонент распознавания речи выдает этот аргумент, значит метрика ошибок данного аргумента, то есть WER, равняется 0%. Если это значение не соответствует пяти часам, то метрика имеет 100% WER. Таким образом, мы просто считаем средневзвешенное значение по всем аргументам и в целом получаем некую агрегированную метрику, оценивающую важность ошибок транскрипций, которые создают компонент распознавания речи. <br/>
<br/>
Приведу в пример эксперименты компании Google, которые она провела в одном из своих исследований на данную тематику. Они использовали данные пяти доменов, пяти тематик: Media, Media_Control, Productivity, Delight, None — с соответствующим им распределением данных на обучающих тестовых наборах данных. Важно отметить, что все модели обучались с нуля. Использовалась cross_entropy, параметр beam search был равен 8, оптимизатор они использовали, естественно, Adam. Считали, конечно же, на большом облаке своих ТПУ. Что получилось в итоге? Такие вот интересные цифры:<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/cj/bb/of/cjbbofaddfuhufwqk3brhr2-l04.png"/><br/>
<br/>
Для понимания, Baseline — это классический подход, который состоит из двух компонентов, как мы в самом начале говорили. Дальше приведены примеры прямой, связанной, мультизадачной и многоступенчатой моделей.<br/>
<br/>
Почем многоступенчатых моделей две? Просто на стыке первой и второй частей использовались разные слои. В первом случае — это ArgMax, во втором случае — SampedSoftmax.<br/>
<br/>
На что стоит обратить внимание? Классический подход проигрывает по всем трем метрикам, которые являются оценкой непосредственно совместной работы двух этих компонентов. Да, нам не интересно, насколько хорошо там делается транскрипция, нам интересно только, насколько хорошо работает элемент, который предсказывает семантическую структуру. Он оценивается тремя метриками: F1 — по тематике, F1 — по интенту и метрикой ArgWer, которая считается по аргументам сущностей. F1 считается средневзвешенной между точностью и полнотой. То есть эталон — это 100. ArgWer — наоборот, это не успешность, это ошибочность, то есть здесь эталон – 0.<br/>
<br/>
Стоит отметить, что наша связанная и мультизадачная модели полностью выигрывают у всех моделей классификации тематик и интентов. А модель, которая является многоступенчатой, имеет очень большой прирост по итоговым ArgWer. Почему это важно? Потому что в задачах, связанных с пониманием разговорной речи, важно конечное действие, которое будет совершаться в компоненте, отвечающем за бизнес-логику. Оно напрямую зависит не от транскрипций, созданной ASR, а от качества работы компонентов ASR и NLU вместе. Поэтому различие почти в три пункта метрики argWER является очень крутым показателем, который говорит об успешности данного подхода. Также стоит отметить, что у всех подходов сопоставимы значения по определению тематики и интентов.<br/>
 <br/>
Приведу пару примеров использования таких алгоритмов понимания разговорной речи. Компания Google, когда говорит про задачи понимания разговорной речи, в первую очередь отмечает интерфейсы «человек-компьютер», то есть это всякие виртуальные помощники типа Google Assistant, Apple Siri, Amazon Alexa и так далее. В качестве второго примера стоит отметить такой пул задач как Interactive Voice Response. То есть это некая история, которая занимается автоматизацией call-центров. <br/>
<br/>
Итак, мы рассмотрели подходы с возможностью использования совместной оптимизации, которая помогает модели сосредоточиться на ошибках, имеющих большее значение для SLU. Такой подход к задаче понимания разговорного языка значительно упрощает общую сложность.<br/>
<br/>
У нас появляется возможность выполнения логического вывода, то есть получения какого-то результата, без необходимости таких дополнительных ресурсов как лексикон, языковые модели, анализаторы и так далее (т.е. вот эти все факторы, которые присущи классическому подходу). Задача решается «напрямую».<br/>
<br/>
На самом деле, можно на этом не останавливаться. И если сейчас мы объединили два подхода, два компонента общей структуры, то можно замахнуться и на большее. Объединить и три компонента, и четыре — просто продолжить объединять эту логическую цепочку и «протаскивать» важность ошибок на уровень ниже, учитывая критичность уже там. Это позволит нам увеличить точность решения задачи.</div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%9C%D0%A2%D0%A1%5D" class="tm-tags-list__link">МТС</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bend-to-end%5D" class="tm-tags-list__link">end-to-end</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%20%D1%80%D0%B5%D1%87%D0%B8%5D" class="tm-tags-list__link">распознавание речи</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%B8%D0%B8%5D" class="tm-tags-list__link">ии</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%5D" class="tm-tags-list__link">машинное обучение</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D1%8C%5D" class="tm-tags-list__link">нейросеть</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%B7%D0%B2%D1%83%D0%BA%5D" class="tm-tags-list__link">звук</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bnlu%5D" class="tm-tags-list__link">nlu</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Basr%5D" class="tm-tags-list__link">asr</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/company/ru_mts/blog/" class="tm-hubs-list__link router-link-active">
    Блог компании МТС
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/algorithms/" class="tm-hubs-list__link">
    Алгоритмы
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/artificial_intelligence/" class="tm-hubs-list__link">
    Искусственный интеллект
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/itcompanies/" class="tm-hubs-list__link">
    IT-компании
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 7: ↑7 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 7: ↑7 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+7</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">21K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    45
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"><div class="tm-article-author__company"><div class="tm-article-author__company-card"><div class="tm-company-snippet"><a href="/ru/company/ru_mts/profile/" class="tm-company-snippet__logo-link"><div class="tm-entity-image"><img alt="" height="40" src="//habrastorage.org/getpro/habr/company/e0b/0e6/247/e0b0e62479e2f247215d4497c4dd88af.png" width="40" class="tm-entity-image__pic"></div></a> <div class="tm-company-snippet__info"><a href="/ru/company/ru_mts/profile/" class="tm-company-snippet__title">МТС</a> <div class="tm-company-snippet__description">Компания</div></div></div> <div class="tm-article-author__buttons"><!----> <!----></div></div> <!----> <div class="tm-article-author__separator"></div></div> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/info_habr/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/66c/94f/0c0/66c94f0c0da486268bb09c00f0b023e3.png" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 84 голоса " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    14
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">9</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><!----> <a href="/ru/users/info_habr/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @info_habr
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Пользователь</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/company/ru_mts/blog/451008/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 1 
    </span></a> <!----></div></div></div>  <!---->  <!----> <!----></div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__placeholder_initial"></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <section class="tm-block tm-block_spacing-bottom"><header class="tm-block__header"><h2 class="tm-block__title">Информация</h2> <!----></header> <div class="tm-block__body"><div class="tm-company-basic-info"><dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата основания</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="1993-04-15T20:00:00.000Z" title="1993-04-16, 00:00">16  апреля  1993</time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Местоположение</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    Россия
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Сайт</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="http://www.mts.ru" target="_blank" class="tm-company-basic-info__link">
      www.mts.ru
    </a></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Численность</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    1 001–5 000 человек
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата регистрации</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2016-08-16T09:35:14.000Z" title="2016-08-16, 12:35">16  августа  2016</time></dd></dl> <!----></div></div> <!----></section> <div class="tm-company-widgets"></div> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/company/ru_mts/blog/451008/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/company/ru_mts/blog/451008/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"451008":{"id":"451008","timePublished":"2019-05-08T11:58:01+00:00","isCorporative":true,"lang":"ru","titleHtml":"End2End-подход к пониманию разговорной речи","leadData":{"textHtml":"\u003Ci\u003EСуществует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент, отвечающий за некую бизнес-логику) и End2End-подход, который предполагает четыре модели реализации: прямую, совместную, многоступенчатую и многозадачную. Рассмотрим все плюсы и минусы этих подходов, в том числе на основе экспериментов компании Google, и подробно разберем, почему End2End-подход решает проблемы классического подхода.\u003Cbr\u003E\r\n\u003C\u002Fi\u003E\u003Cbr\u003E\r\n\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F4f\u002Fzx\u002Fo3\u002F4fzxo3p37pnl9kprkwk1trmwxd4.png\"\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше →","image":null},"editorVersion":"1.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":14,"votesCount":84},"rating":9,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"1280442","alias":"info_habr","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F66c\u002F94f\u002F0c0\u002F66c94f0c0da486268bb09c00f0b023e3.png","speciality":"Пользователь"},"statistics":{"commentsCount":1,"favoritesCount":45,"readingCount":20835,"score":7,"votesCount":7},"hubs":[{"relatedData":null,"id":"20822","alias":"ru_mts","type":"corporative","title":"Блог компании МТС","titleHtml":"Блог компании МТС","isProfiled":false},{"relatedData":null,"id":"8000","alias":"algorithms","type":"collective","title":"Алгоритмы","titleHtml":"Алгоритмы","isProfiled":true},{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true},{"relatedData":null,"id":"21922","alias":"artificial_intelligence","type":"collective","title":"Искусственный интеллект","titleHtml":"Искусственный интеллект","isProfiled":false},{"relatedData":null,"id":"22026","alias":"itcompanies","type":"collective","title":"IT-компании","titleHtml":"IT-компании","isProfiled":false}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Ci\u003EСуществует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент, отвечающий за некую бизнес-логику) и End2End-подход, который предполагает четыре модели реализации: прямую, совместную, многоступенчатую и многозадачную. Рассмотрим все плюсы и минусы этих подходов, в том числе на основе экспериментов компании Google, и подробно разберем, почему End2End-подход решает проблемы классического подхода.\u003Cbr\u002F\u003E\r\n\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F4f\u002Fzx\u002Fo3\u002F4fzxo3p37pnl9kprkwk1trmwxd4.png\"\u002F\u003E\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПередаем слово ведущему разработчику центра AI МТС Никите Семенову.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПривет! В качестве предисловия хочу процитировать всем известных ученых Яна Лекуна, Иошуа Бенджио и Джеффри Хинтона — это три пионера искусственного интеллекта, которые недавно получили одну из самых престижных премий в области информационных технологий — премию Тьюринга. В одном из выпусков журнала Nature в 2015 году они выпустили очень интересную статью «Deep learning», в которой была занимательная фраза: «Deep learning came with the promise of its capability to deal with raw signals without the need for hand-crafted features». Ее трудно корректно перевести, но смысл примерно такой: «Глубокое обучение пришло с обещанием возможности справляться с сырыми сигналами без необходимости ручного создания признаков». На мой взгляд, для разработчиков это главный мотиватор из всех существующих. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EКлассический подход\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\n\u2028Итак, начнем с классического подхода. Когда мы говорим про понимание разговорной речи машиной, мы подразумеваем, что у нас есть некий человек, который хочет управлять какими-то сервисами с помощью своего голоса или испытывает потребность в том, чтобы какая-то система отвечала на его голосовые команды некой логикой. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКак решается такая задача? В классическом варианте используется система, которая, как было сказано выше, состоит из трех крупных компонентов: компонента распознавания речи, компонента понимания естественного языка и компонента, отвечающего за некую бизнес-логику. Понятно, что вначале пользователь создает некий звуковой сигнал, который попадает на компонент распознавания речи и превращается из звука в текст. Затем текст попадает в компонент понимания естественного языка, откуда вытаскивается некая семантическая структура, которая необходима для компонента, отвечающего за бизнес-логику. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fsl\u002Fs9\u002Fa1\u002Fsls9a1uzwmia7h523tecvgssiec.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u2028\u2028Что из себя представляет семантическая структура? Это некое обобщение\u002Fагрегация нескольких задач в одну — для удобства понимания. Структура включает в себя три важных части: классификацию домена (некое определение тематики), классификацию интента (понимание, а что собственно нужно сделать) и выделение именованных сущностей для заполнения карточек, которые необходимы для конкретных бизнес-задач на следующем этапе.\u2028\u2028Чтобы понять, что такое семантическая структура, можно рассмотреть простой пример, который чаще всего приводит компания Google. У нас имеется простой запрос: «Пожалуйста, проиграй какую-то песню какого-то артиста». \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fnf\u002Fan\u002F6l\u002Fnfan6l3vzzjsl_r4iq9_3x491rk.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДомен и тематика в этом запросе — музыка; интент — проиграй песню; атрибуты карточки «проиграй песню» — что за песня, какой артист. Такая структура — результат понимания естественного языка. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли говорить про решение комплексной и многоэтапной задачи понимание разговорной речи, то она, как я уже сказал, состоит из двух этапов: первый — распознавание речи, второй — понимание естественного языка. Классический подход подразумевает полное разделение этих этапов. В качестве первого шага у нас есть некая модель, которая на входе получает акустический сигнал, и на выходе, используя языковую и акустические модели и лексикон, определяет наиболее вероятную словесную гипотезу из этого акустического сигнала. Это полностью вероятностная история — ее можно разложить по известной формуле Байеса и получить формулу, которая позволяет записать функцию правдоподобия выборки и воспользоваться методом максимального правдоподобия. У нас есть условная вероятность сигнала Х при условии словесной последовательности W, которая умножается на вероятность этой словесной последовательности.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fu0\u002Fpz\u002Fy8\u002Fu0pzy8cvkx_texgnjfzun-keavu.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПервый этап мы прошли — получили из звукового сигнала некую словесную гипотезу. Дальше вступает в ход второй компонент, который берет эту самую словесную гипотезу и пытается из нее вытащить семантическую структуру, описанную нами выше. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУ нас есть вероятность семантической структуры S при условии словесной последовательности W на входе.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fyi\u002F34\u002Ftx\u002Fyi34txzqvgevrvoauj4stho32im.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЧем плох классической подход, состоящий из двух этих элементов\u002Fшагов, которые обучаются раздельно (т.е. мы сначала обучаем модель первого элемента, а затем модель второго)? \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003EКомпонент понимания естественного языка работает с высокоуровневыми словесными гипотезами, которые генерирует ASR. Это большая проблема, потому что первый компонент (сам ASR) работает с низкоуровневыми сырыми данными и генерирует высокоуровневую словесную гипотезу, а второй компонент берет на вход уже гипотезу — не сырые данные из первоисточника, а гипотезу, которую дает первая модель — и строит свою гипотезу над гипотезой первого этапа. Это довольно проблематичная история, потому что она становится слишком «условной».\u003C\u002Fli\u003E\r\n\u003Cli\u003EСледующая проблема: мы никак не можем построить связь между важностью слов, которые необходимы для построения той самой семантической структуры, и тем, чему отдает предпочтение первый компонент, строя свою словесную гипотезу. То есть если перефразировать, у нас получается, что гипотеза уже построена. Она строится на основе трех компонентов, как я уже сказал: акустическая часть (то, что пришло на вход и как-то моделируется), языковая часть (полностью моделирует какие-нибудь языковые энграммы — вероятность речи) и лексикон (произношение слов). Это три большие части, которые нужно совместить и найти в них какую-то гипотезу. Но нет возможности влиять на выбор той самой гипотезы так, чтобы эта гипотеза была важна следующему этапу (что в принципе заключается в пункте, что они обучаются полностью раздельно и никак друг на друга не влияют). \u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EEnd2End-подход\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nМы поняли, что такое классический подход, какие у него есть проблемы. Попробуем решить эти проблемы при помощи End2End-подхода. \u2028\u2028\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПод End2End мы подразумеваем модель, которая соединит различные компоненты в единый компонент. Моделировать мы будем с помощью моделей, которые состоят из архитектуры encoder-decoder, содержащие модули внимание (attention). Такие архитектуры часто используются в задачах распознавания речи и в задачах, связанных с обработкой естественного языка, в частности, машинного перевода. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМожно выделить четыре варианта реализации таких подходов, которые могли бы решать поставленную перед нами проблему классического подхода: это прямая, совместная, многоступенчатая и многозадачная модели.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EПрямая модель\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nПрямая модель берет на вход низкоуровневые сырые признаки, т.е. низкоуровневый аудиосигнал, а на выходе мы сразу получаем семантическую структуру. То есть у нас получается один модуль — вход первого модуля из классического подхода и выход второго модуля из того же классического подхода. Просто такой «черный ящик». Отсюда возникают некоторые плюсы и некоторые минусы. Модель не учится полностью транскрибировать входной сигнал — это явный плюс, потому что нам не нужно собирать большую-большую разметку, не нужно собирать много аудиосигнала, а потом отдавать его ассесорам на разметку. Нам лишь нужен этот аудиосигнал и соответствующая ему семантическая структура. И все. Это во много раз снижает трудозатраты на разметку данных. Наверное, самый большой минус такого подхода в том, что задача слишком сложная для такого «черного ящика», который пытается решить сразу, условно, две задачи. Сначала внутри себя он пытается построить некую транскрипцию, а потом из этой транскрипции выявить ту самую семантическую структуру. Тут встает довольно сложная задача — научиться игнорировать части транскрипции. А это очень сложно. Этот фактор является довольно большим и колоссальным минусом такого подхода. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u2028\u2028Если говорить про вероятности, то данной моделью решается задача поиска наиболее вероятной семантической структуры S из акустического сигнала X с параметрами модели θ. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F34\u002Fkl\u002Fm2\u002F34klm26dj3vk5sd9kdcxckkenii.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EСовместная модель\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nКакая существует альтернатива? Это совместная модель. То есть какая-то модель очень похожая на прямую, но за одним исключением: выход у нас уже состоит из словесных последовательностей и к ним просто конкатенируется семантическая структура. То есть у нас на входе есть звуковой сигнал и нейросетевая модель, которая на выходе уже дает одновременно и словесную транскрипцию, и семантическую структуру.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fjz\u002Fkn\u002F-f\u002Fjzkn-frploycnewpluip2kgoqb8.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИз плюсов: у нас сохраняется простой энкодер, простой декодер. Облегчается обучение, потому что модель не пытается решить сразу две задачи, как в случае прямой модели. Еще из плюсов можно отметить, что все-таки присутствует вот эта зависимость семантической структуры от низкоуровневых звуковых признаков. Потому что опять-таки один энкодер, один декодер. И, соответственно, еще из плюсов можно отметить, что присутствует зависимость в предсказании этой самой семантической структуры и ее влиянии непосредственно на саму транскрипцию — что нас не устраивало в классическом подходе.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОпять-таки нам надо найти наиболее вероятную последовательность слов W и соответствующие им семантические структуры S из акустического сигнала X с параметрами θ. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EМногозадачная модель\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nСледующий подход — это многозадачная модель. Опять-таки энкодер-декодер подход, но за одним исключением. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fym\u002Fkz\u002Fl3\u002Fymkzl3t_nh892ohttlu84sjg98i.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНа каждую задачу, то есть на создание словесной последовательности, на создание семантической структуры у нас свой декодер, использующий одно общее скрытое представление, которое генерирует единый энкодер. Очень известный трюк в машинном обучении, очень часто используется в работах. Решение сразу двух неодинаковых задач помогает намного лучше искать зависимости в исходных данных. И как следствие этого — лучшая обобщающая способность, так как выбирается оптимальный параметр сразу для нескольких задач. Такой подход более всего подходит для задач с меньшим количеством данных. И декодеры используют одно скрытое векторное пространство, в которое создает их энкодер. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F8l\u002F-q\u002Fpj\u002F8l-qpjo3dccdzmqh5a-fspmveiq.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВажно отметить, что уже в вероятности появляется зависимость от параметров моделей энкодера и декодера. И параметры эти важные.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EМногоступенчатая модель\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nПерейдем, на мой взгляд, к самому интересному подходу: многоступенчатой модели. Если очень внимательно посмотреть, можно увидеть, что на самом деле это тот же самый двухкомпонентный классический подход за одним только исключением. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ffr\u002Faz\u002Fnp\u002Ffraznpocvjmklcjjmau4i9v9ago.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТут существует возможность установить связь между модулями и сделать их одномодульными. Поэтому семантическая структура считается условно зависимой от транскрипции. Есть два варианта работы с этой моделью. Мы можем обучать по отдельности два эти мини-блока: первый и второй энкодер-декодер. Или совместить их и обучать одновременно обе задачи.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ первом случае параметры для двух задач не связаны (мы можем обучать, используя разные данные). Допустим, у нас есть большой корпус звука и соответствующие ему словесные последовательности и транскрипции. Мы «загоняем» их, обучаем только первую часть. Получаем в хорошем моделировании транскрипции. Потом берем вторую часть, обучаем на другом корпусе. Соединяем и получаем решение, которое в таком подходе на 100% соответствует классическому подходу, потому что мы отдельно взяли и обучили первую часть и отдельно — вторую. А дальше мы обучаем соединенную модель на корпусе, который уже содержит триады данных: звуковой сигнал, соответствующая ему транскрипция и соответствующая ей семантическая структура. Если у нас есть такой корпус, мы можем дообучить обученную по отдельности на больших корпусах модель на нашу конкретную небольшую задачку и получить вот таким вот хитрым способом максимальный выигрыш по точности. Такой подход нам позволяет учитывать важность разных частей транскрипции и их влияние на предсказание семантической структуры с помощью \u003Ci\u003Eучета ошибки\u003C\u002Fi\u003E второго этапа в первом. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВажно отметить, что итоговая задача очень похожа на классический подход за одним только большим отличием: второй член нашей функции — логарифм вероятности семантической структуры — при условии входного акустического сигнала Х зависит так же еще от параметров \u003Ci\u003Eмодели первого этапа\u003C\u002Fi\u003E. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fpa\u002F24\u002Fxr\u002Fpa24xr-aaep-mqo7bzd3loksve4.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗдесь также важно отметить, что второй компонент зависит от параметров первой и второй модели.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EМетодика оценки точности подходов\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nТеперь стоит определиться с методикой оценки точности. Как, собственно, эту точность мерить, чтобы учитывать особенности, которые нас не устраивают в классическом подходе? Существуют классические метки для этих раздельных задач. Для оценки компонентов распознавания речи мы можем взять классическую метрику WER. Это Word Error Rate. Считаем по не очень сложной формуле количество вставок, замен, перестановок слова и делим их на количество всех слов. И получаем некую оценочную характеристику качества нашего распознавания. Для семантической структуры покомпонентно мы можем просто считать F1 score. Это тоже некая классическая метрика для задачи классификации. Тут все плюс-минус понятно. Есть полнота, есть точность. И это просто гармоническое среднее между ними. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНо возникает вопрос, как измерять точность, когда входная транскрипция и выходной аргумент не совпадают или когда выходные данные являются аудиоданными. Компанией Google была предложена метрика, которая будет учитывать важность предсказания первого компонента распознавания речи путем оценки влияния этого самого распознавания на непосредственно второй компонент. Они назвали ее Arg WER, то есть это взвешивание WER по сущностям семантической структуры. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВозьмем запрос: «Поставь будильник на 5 часов». Данная семантическая структура содержит такой аргумент, как «пять часов», аргумент типа «date time». Важно понимать, если компонент распознавания речи выдает этот аргумент, значит метрика ошибок данного аргумента, то есть WER, равняется 0%. Если это значение не соответствует пяти часам, то метрика имеет 100% WER. Таким образом, мы просто считаем средневзвешенное значение по всем аргументам и в целом получаем некую агрегированную метрику, оценивающую важность ошибок транскрипций, которые создают компонент распознавания речи. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПриведу в пример эксперименты компании Google, которые она провела в одном из своих исследований на данную тематику. Они использовали данные пяти доменов, пяти тематик: Media, Media_Control, Productivity, Delight, None — с соответствующим им распределением данных на обучающих тестовых наборах данных. Важно отметить, что все модели обучались с нуля. Использовалась cross_entropy, параметр beam search был равен 8, оптимизатор они использовали, естественно, Adam. Считали, конечно же, на большом облаке своих ТПУ. Что получилось в итоге? Такие вот интересные цифры:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fcj\u002Fbb\u002Fof\u002Fcjbbofaddfuhufwqk3brhr2-l04.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДля понимания, Baseline — это классический подход, который состоит из двух компонентов, как мы в самом начале говорили. Дальше приведены примеры прямой, связанной, мультизадачной и многоступенчатой моделей.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПочем многоступенчатых моделей две? Просто на стыке первой и второй частей использовались разные слои. В первом случае — это ArgMax, во втором случае — SampedSoftmax.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНа что стоит обратить внимание? Классический подход проигрывает по всем трем метрикам, которые являются оценкой непосредственно совместной работы двух этих компонентов. Да, нам не интересно, насколько хорошо там делается транскрипция, нам интересно только, насколько хорошо работает элемент, который предсказывает семантическую структуру. Он оценивается тремя метриками: F1 — по тематике, F1 — по интенту и метрикой ArgWer, которая считается по аргументам сущностей. F1 считается средневзвешенной между точностью и полнотой. То есть эталон — это 100. ArgWer — наоборот, это не успешность, это ошибочность, то есть здесь эталон – 0.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСтоит отметить, что наша связанная и мультизадачная модели полностью выигрывают у всех моделей классификации тематик и интентов. А модель, которая является многоступенчатой, имеет очень большой прирост по итоговым ArgWer. Почему это важно? Потому что в задачах, связанных с пониманием разговорной речи, важно конечное действие, которое будет совершаться в компоненте, отвечающем за бизнес-логику. Оно напрямую зависит не от транскрипций, созданной ASR, а от качества работы компонентов ASR и NLU вместе. Поэтому различие почти в три пункта метрики argWER является очень крутым показателем, который говорит об успешности данного подхода. Также стоит отметить, что у всех подходов сопоставимы значения по определению тематики и интентов.\u003Cbr\u002F\u003E\r\n \u003Cbr\u002F\u003E\r\nПриведу пару примеров использования таких алгоритмов понимания разговорной речи. Компания Google, когда говорит про задачи понимания разговорной речи, в первую очередь отмечает интерфейсы «человек-компьютер», то есть это всякие виртуальные помощники типа Google Assistant, Apple Siri, Amazon Alexa и так далее. В качестве второго примера стоит отметить такой пул задач как Interactive Voice Response. То есть это некая история, которая занимается автоматизацией call-центров. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИтак, мы рассмотрели подходы с возможностью использования совместной оптимизации, которая помогает модели сосредоточиться на ошибках, имеющих большее значение для SLU. Такой подход к задаче понимания разговорного языка значительно упрощает общую сложность.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУ нас появляется возможность выполнения логического вывода, то есть получения какого-то результата, без необходимости таких дополнительных ресурсов как лексикон, языковые модели, анализаторы и так далее (т.е. вот эти все факторы, которые присущи классическому подходу). Задача решается «напрямую».\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНа самом деле, можно на этом не останавливаться. И если сейчас мы объединили два подхода, два компонента общей структуры, то можно замахнуться и на большее. Объединить и три компонента, и четыре — просто продолжить объединять эту логическую цепочку и «протаскивать» важность ошибок на уровень ниже, учитывая критичность уже там. Это позволит нам увеличить точность решения задачи.\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"МТС"},{"titleHtml":"end-to-end"},{"titleHtml":"распознавание речи"},{"titleHtml":"ии"},{"titleHtml":"машинное обучение"},{"titleHtml":"нейросеть"},{"titleHtml":"звук"},{"titleHtml":"nlu"},{"titleHtml":"asr"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F451008\u002F2479b560db4728453d90d9d179a650d7\u002F","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F451008\u002F2479b560db4728453d90d9d179a650d7\u002F?format=vk","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fru_mts\\\u002Fblog\\\u002F451008\\\u002F\"},\"headline\":\"End2End-подход к пониманию разговорной речи\",\"datePublished\":\"2019-05-08T14:58:01+03:00\",\"dateModified\":\"2019-05-08T15:45:58+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"info_habr\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимани...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fru_mts\\\u002Fblog\\\u002F451008\\\u002F#post-content-body\",\"about\":[\"c_ru_mts\",\"h_algorithms\",\"h_machine_learning\",\"h_artificial_intelligence\",\"h_itcompanies\",\"f_develop\",\"f_popsci\"],\"image\":[\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F4f\\\u002Fzx\\\u002Fo3\\\u002F4fzxo3p37pnl9kprkwk1trmwxd4.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fsl\\\u002Fs9\\\u002Fa1\\\u002Fsls9a1uzwmia7h523tecvgssiec.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fnf\\\u002Fan\\\u002F6l\\\u002Fnfan6l3vzzjsl_r4iq9_3x491rk.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fu0\\\u002Fpz\\\u002Fy8\\\u002Fu0pzy8cvkx_texgnjfzun-keavu.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fyi\\\u002F34\\\u002Ftx\\\u002Fyi34txzqvgevrvoauj4stho32im.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F34\\\u002Fkl\\\u002Fm2\\\u002F34klm26dj3vk5sd9kdcxckkenii.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fjz\\\u002Fkn\\\u002F-f\\\u002Fjzkn-frploycnewpluip2kgoqb8.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fym\\\u002Fkz\\\u002Fl3\\\u002Fymkzl3t_nh892ohttlu84sjg98i.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F8l\\\u002F-q\\\u002Fpj\\\u002F8l-qpjo3dccdzmqh5a-fspmveiq.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ffr\\\u002Faz\\\u002Fnp\\\u002Ffraznpocvjmklcjjmau4i9v9ago.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fpa\\\u002F24\\\u002Fxr\\\u002Fpa24xr-aaep-mqo7bzd3loksve4.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fcj\\\u002Fbb\\\u002Fof\\\u002Fcjbbofaddfuhufwqk3brhr2-l04.png\"]}","metaDescription":"Существует несколько подходов к понимаю машиной разговорной речи: классический трехкомпонентный подход (включает компонент распознавания речи, компонент понимания естественного языка и компонент,...","mainImageUrl":null,"amp":true},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":""},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{"ru_mts":{"alias":"ru_mts","imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fcompany\u002Fe0b\u002F0e6\u002F247\u002Fe0b0e62479e2f247215d4497c4dd88af.png","titleHtml":"МТС","descriptionHtml":null,"relatedData":null,"statistics":{"postsCount":60,"newsCount":0,"vacanciesCount":0,"employeesCount":25,"careerRating":null,"subscribersCount":17993,"rating":130.5,"invest":null},"foundationDate":{"year":"1993","month":"04","day":"16"},"location":{"city":{"id":"447159","title":"Москва"},"region":{"id":"1885","title":"Москва и Московская обл."},"country":{"id":"168","title":"Россия"}},"siteUrl":"http:\u002F\u002Fwww.mts.ru","staffNumber":"1 001–5 000 человек","registrationDate":"2016-08-16T09:35:14+00:00","representativeUser":null,"contacts":[],"settings":{"analyticsSettings":[],"branding":null,"status":"active"},"metadata":{"titleHtml":"МТС, Москва -  с 16 апреля 1993 г.","title":"МТС, Москва -  с 16 апреля 1993 г.","keywords":["Машинное обучение","Natural Language Processing","Data Mining","Искусственный интеллект","Управление разработкой"],"descriptionHtml":"60 статей от авторов компании МТС","description":"60 статей от авторов компании МТС"},"aDeskSettings":null,"careerAlias":"mts","maxCustomTrackerLinks":0}},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
